{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Emotions.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKeXPTgn6-sW"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import scipy\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "from IPython.display import Audio\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "%matplotlib inline\r\n",
        "from keras import layers\r\n",
        "import keras\r\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yhq4yvG2grGI",
        "outputId": "f63a652a-d793-4c40-d45e-ead3a33c3297"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SafwT2Vsg9Kt"
      },
      "source": [
        "!unzip -q /content/drive/MyDrive/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "L3bgSd_07KLJ",
        "outputId": "86aaacc3-06d1-4dd5-ad9a-d8b2cdf613f5"
      },
      "source": [
        "df1 = pd.read_csv('/content/Data/features_3_sec.csv')\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blues.00000.0.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.335406</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.003521</td>\n",
              "      <td>1773.065032</td>\n",
              "      <td>167541.63090</td>\n",
              "      <td>1972.744388</td>\n",
              "      <td>117335.77160</td>\n",
              "      <td>3714.560359</td>\n",
              "      <td>1.080790e+06</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>-0.000078</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>0.005535</td>\n",
              "      <td>129.199219</td>\n",
              "      <td>-118.627914</td>\n",
              "      <td>2440.286621</td>\n",
              "      <td>125.083626</td>\n",
              "      <td>260.956909</td>\n",
              "      <td>-23.443724</td>\n",
              "      <td>364.081726</td>\n",
              "      <td>41.321484</td>\n",
              "      <td>181.694855</td>\n",
              "      <td>-5.976108</td>\n",
              "      <td>152.963135</td>\n",
              "      <td>20.115141</td>\n",
              "      <td>75.652298</td>\n",
              "      <td>-16.045410</td>\n",
              "      <td>40.227104</td>\n",
              "      <td>17.855198</td>\n",
              "      <td>84.320282</td>\n",
              "      <td>-14.633434</td>\n",
              "      <td>83.437233</td>\n",
              "      <td>10.270527</td>\n",
              "      <td>97.001335</td>\n",
              "      <td>-9.708279</td>\n",
              "      <td>66.669891</td>\n",
              "      <td>10.183875</td>\n",
              "      <td>45.103611</td>\n",
              "      <td>-4.681614</td>\n",
              "      <td>34.169498</td>\n",
              "      <td>8.417439</td>\n",
              "      <td>48.269444</td>\n",
              "      <td>-7.233477</td>\n",
              "      <td>42.770947</td>\n",
              "      <td>-2.853603</td>\n",
              "      <td>39.687145</td>\n",
              "      <td>-3.241280</td>\n",
              "      <td>36.488243</td>\n",
              "      <td>0.722209</td>\n",
              "      <td>38.099152</td>\n",
              "      <td>-5.050335</td>\n",
              "      <td>33.618073</td>\n",
              "      <td>-0.243027</td>\n",
              "      <td>43.771767</td>\n",
              "      <td>blues</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blues.00000.1.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.343065</td>\n",
              "      <td>0.086147</td>\n",
              "      <td>0.112699</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>1816.693777</td>\n",
              "      <td>90525.69087</td>\n",
              "      <td>2010.051501</td>\n",
              "      <td>65671.87567</td>\n",
              "      <td>3869.682242</td>\n",
              "      <td>6.722448e+05</td>\n",
              "      <td>0.087173</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>-0.000103</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-125.590706</td>\n",
              "      <td>2038.344238</td>\n",
              "      <td>122.421226</td>\n",
              "      <td>216.774185</td>\n",
              "      <td>-20.718019</td>\n",
              "      <td>231.979767</td>\n",
              "      <td>50.128387</td>\n",
              "      <td>142.700409</td>\n",
              "      <td>-11.333303</td>\n",
              "      <td>139.243118</td>\n",
              "      <td>21.385401</td>\n",
              "      <td>77.817947</td>\n",
              "      <td>-15.960796</td>\n",
              "      <td>97.364029</td>\n",
              "      <td>19.454103</td>\n",
              "      <td>57.948093</td>\n",
              "      <td>-12.465918</td>\n",
              "      <td>68.271523</td>\n",
              "      <td>17.898169</td>\n",
              "      <td>56.222176</td>\n",
              "      <td>-11.732554</td>\n",
              "      <td>54.373909</td>\n",
              "      <td>8.145000</td>\n",
              "      <td>40.662876</td>\n",
              "      <td>-7.717751</td>\n",
              "      <td>30.808521</td>\n",
              "      <td>8.397150</td>\n",
              "      <td>48.784225</td>\n",
              "      <td>-8.300493</td>\n",
              "      <td>68.584824</td>\n",
              "      <td>4.074709</td>\n",
              "      <td>64.748276</td>\n",
              "      <td>-6.055294</td>\n",
              "      <td>40.677654</td>\n",
              "      <td>0.159015</td>\n",
              "      <td>51.264091</td>\n",
              "      <td>-2.837699</td>\n",
              "      <td>97.030830</td>\n",
              "      <td>5.784063</td>\n",
              "      <td>59.943081</td>\n",
              "      <td>blues</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blues.00000.2.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.346815</td>\n",
              "      <td>0.092243</td>\n",
              "      <td>0.132003</td>\n",
              "      <td>0.004620</td>\n",
              "      <td>1788.539719</td>\n",
              "      <td>111407.43760</td>\n",
              "      <td>2084.565132</td>\n",
              "      <td>75124.92172</td>\n",
              "      <td>3997.639160</td>\n",
              "      <td>7.907127e+05</td>\n",
              "      <td>0.071383</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.012476</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.004357</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-132.441940</td>\n",
              "      <td>3798.532227</td>\n",
              "      <td>115.085175</td>\n",
              "      <td>257.321289</td>\n",
              "      <td>-14.811666</td>\n",
              "      <td>192.448074</td>\n",
              "      <td>50.189293</td>\n",
              "      <td>144.166031</td>\n",
              "      <td>-0.680819</td>\n",
              "      <td>128.376892</td>\n",
              "      <td>24.650375</td>\n",
              "      <td>66.371170</td>\n",
              "      <td>-13.506104</td>\n",
              "      <td>89.319336</td>\n",
              "      <td>15.643386</td>\n",
              "      <td>55.253967</td>\n",
              "      <td>-13.216637</td>\n",
              "      <td>120.308785</td>\n",
              "      <td>10.406025</td>\n",
              "      <td>35.757862</td>\n",
              "      <td>-7.991465</td>\n",
              "      <td>47.911613</td>\n",
              "      <td>11.853963</td>\n",
              "      <td>36.569931</td>\n",
              "      <td>-4.677677</td>\n",
              "      <td>40.725075</td>\n",
              "      <td>6.571110</td>\n",
              "      <td>30.686846</td>\n",
              "      <td>-2.424750</td>\n",
              "      <td>50.313499</td>\n",
              "      <td>4.806280</td>\n",
              "      <td>67.336563</td>\n",
              "      <td>-1.768610</td>\n",
              "      <td>28.348579</td>\n",
              "      <td>2.378768</td>\n",
              "      <td>45.717648</td>\n",
              "      <td>-1.938424</td>\n",
              "      <td>53.050835</td>\n",
              "      <td>2.517375</td>\n",
              "      <td>33.105122</td>\n",
              "      <td>blues</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blues.00000.3.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.363639</td>\n",
              "      <td>0.086856</td>\n",
              "      <td>0.132565</td>\n",
              "      <td>0.002448</td>\n",
              "      <td>1655.289045</td>\n",
              "      <td>111952.28450</td>\n",
              "      <td>1960.039988</td>\n",
              "      <td>82913.63927</td>\n",
              "      <td>3568.300218</td>\n",
              "      <td>9.216524e+05</td>\n",
              "      <td>0.069426</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>0.008318</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.005927</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-118.231087</td>\n",
              "      <td>2508.781006</td>\n",
              "      <td>132.116501</td>\n",
              "      <td>332.650574</td>\n",
              "      <td>-18.758335</td>\n",
              "      <td>109.357529</td>\n",
              "      <td>39.769306</td>\n",
              "      <td>184.693344</td>\n",
              "      <td>-13.260426</td>\n",
              "      <td>144.398224</td>\n",
              "      <td>20.468134</td>\n",
              "      <td>122.516464</td>\n",
              "      <td>-14.563448</td>\n",
              "      <td>68.937332</td>\n",
              "      <td>18.745104</td>\n",
              "      <td>74.748886</td>\n",
              "      <td>-13.755463</td>\n",
              "      <td>73.868576</td>\n",
              "      <td>12.993759</td>\n",
              "      <td>41.549564</td>\n",
              "      <td>-12.648887</td>\n",
              "      <td>58.540478</td>\n",
              "      <td>10.389314</td>\n",
              "      <td>39.102024</td>\n",
              "      <td>-4.362739</td>\n",
              "      <td>60.714748</td>\n",
              "      <td>9.156193</td>\n",
              "      <td>40.411537</td>\n",
              "      <td>-9.889441</td>\n",
              "      <td>44.666325</td>\n",
              "      <td>-1.359111</td>\n",
              "      <td>47.739452</td>\n",
              "      <td>-3.841155</td>\n",
              "      <td>28.337118</td>\n",
              "      <td>1.218588</td>\n",
              "      <td>34.770935</td>\n",
              "      <td>-3.580352</td>\n",
              "      <td>50.836224</td>\n",
              "      <td>3.630866</td>\n",
              "      <td>32.023678</td>\n",
              "      <td>blues</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blues.00000.4.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.335579</td>\n",
              "      <td>0.088129</td>\n",
              "      <td>0.143289</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>1630.656199</td>\n",
              "      <td>79667.26765</td>\n",
              "      <td>1948.503884</td>\n",
              "      <td>60204.02027</td>\n",
              "      <td>3469.992864</td>\n",
              "      <td>6.102111e+05</td>\n",
              "      <td>0.070095</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-105.968376</td>\n",
              "      <td>2118.919922</td>\n",
              "      <td>134.643646</td>\n",
              "      <td>219.562622</td>\n",
              "      <td>-19.961748</td>\n",
              "      <td>171.878754</td>\n",
              "      <td>40.171753</td>\n",
              "      <td>103.120712</td>\n",
              "      <td>-14.271939</td>\n",
              "      <td>102.651230</td>\n",
              "      <td>18.734617</td>\n",
              "      <td>79.070000</td>\n",
              "      <td>-15.619381</td>\n",
              "      <td>48.510284</td>\n",
              "      <td>19.207966</td>\n",
              "      <td>53.642956</td>\n",
              "      <td>-18.274683</td>\n",
              "      <td>95.300995</td>\n",
              "      <td>14.316693</td>\n",
              "      <td>58.821163</td>\n",
              "      <td>-5.792194</td>\n",
              "      <td>55.030254</td>\n",
              "      <td>17.045437</td>\n",
              "      <td>43.229939</td>\n",
              "      <td>-5.681399</td>\n",
              "      <td>46.515259</td>\n",
              "      <td>5.705521</td>\n",
              "      <td>24.956211</td>\n",
              "      <td>-7.986080</td>\n",
              "      <td>39.816933</td>\n",
              "      <td>2.092937</td>\n",
              "      <td>30.336359</td>\n",
              "      <td>0.664582</td>\n",
              "      <td>45.880913</td>\n",
              "      <td>1.689446</td>\n",
              "      <td>51.363583</td>\n",
              "      <td>-3.392489</td>\n",
              "      <td>26.738789</td>\n",
              "      <td>0.536961</td>\n",
              "      <td>29.146694</td>\n",
              "      <td>blues</td>\n",
              "      <td>happiness</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            filename  length  chroma_stft_mean  ...  mfcc20_var  label    emotion\n",
              "0  blues.00000.0.wav   66149          0.335406  ...   43.771767  blues  happiness\n",
              "1  blues.00000.1.wav   66149          0.343065  ...   59.943081  blues  happiness\n",
              "2  blues.00000.2.wav   66149          0.346815  ...   33.105122  blues  happiness\n",
              "3  blues.00000.3.wav   66149          0.363639  ...   32.023678  blues  happiness\n",
              "4  blues.00000.4.wav   66149          0.335579  ...   29.146694  blues  happiness\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YomOGdeLEUYv",
        "outputId": "dda8bd4b-66ce-48f5-b39f-971586e77a95"
      },
      "source": [
        "# df1.dtypes\r\n",
        "df1 = df1.drop(labels='filename',axis=1)\r\n",
        "df1 = df1.drop(labels='label', axis=1)\r\n",
        "emotion_list = df1.iloc[:, -1]\r\n",
        "encoder = LabelEncoder()\r\n",
        "y = encoder.fit_transform(emotion_list)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 3 3 3]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AesOJLuZEchC",
        "outputId": "19cf23a4-7e9e-4b3b-b2f9-d05a6a0094b0"
      },
      "source": [
        "print(df1.iloc[:, :-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      length  chroma_stft_mean  ...  mfcc20_mean  mfcc20_var\n",
            "0      66149          0.335406  ...    -0.243027   43.771767\n",
            "1      66149          0.343065  ...     5.784063   59.943081\n",
            "2      66149          0.346815  ...     2.517375   33.105122\n",
            "3      66149          0.363639  ...     3.630866   32.023678\n",
            "4      66149          0.335579  ...     0.536961   29.146694\n",
            "...      ...               ...  ...          ...         ...\n",
            "9985   66149          0.349126  ...     1.818823   38.966969\n",
            "9986   66149          0.372564  ...     0.428857   18.697033\n",
            "9987   66149          0.347481  ...    -0.299545   41.586990\n",
            "9988   66149          0.387527  ...     0.675824   12.787750\n",
            "9989   66149          0.369293  ...    -3.412534   31.727489\n",
            "\n",
            "[9990 rows x 58 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ovbwx_RlEiNA",
        "outputId": "6fad550e-b7d5-42ec-977c-4a908fd1e6e3"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "X = scaler.fit_transform(np.array(df1.iloc[:, :-1], dtype = float))\r\n",
        "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, test_size=0.2)\r\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, test_size=0.5)\r\n",
        "from keras.models import Sequential\r\n",
        "# Neural network\r\n",
        "model = Sequential()\r\n",
        "model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(64, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(64, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.5))\r\n",
        "model.add(layers.Dense(4, activation='softmax'))\r\n",
        "opt = SGD(learning_rate=1e-2, momentum=0.9, nesterov=True)\r\n",
        "model.compile(optimizer=opt,\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               7552      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 260       \n",
            "=================================================================\n",
            "Total params: 20,228\n",
            "Trainable params: 20,228\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUVWtpuCP0_o",
        "outputId": "4f210229-3731-4f0e-bd60-6aa5a9ef67e8"
      },
      "source": [
        "classifier = model.fit(X_train,\r\n",
        "                    y_train,\r\n",
        "                    epochs=300,\r\n",
        "                    batch_size=128, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/300\n",
            "63/63 [==============================] - 2s 5ms/step - loss: 1.5362 - accuracy: 0.3276 - val_loss: 1.2715 - val_accuracy: 0.4284\n",
            "Epoch 2/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.2805 - accuracy: 0.4216 - val_loss: 1.2434 - val_accuracy: 0.4284\n",
            "Epoch 3/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.2456 - accuracy: 0.4356 - val_loss: 1.2213 - val_accuracy: 0.4274\n",
            "Epoch 4/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.2292 - accuracy: 0.4327 - val_loss: 1.2121 - val_accuracy: 0.4274\n",
            "Epoch 5/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.2116 - accuracy: 0.4366 - val_loss: 1.2077 - val_accuracy: 0.4294\n",
            "Epoch 6/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.2125 - accuracy: 0.4454 - val_loss: 1.2036 - val_accuracy: 0.4294\n",
            "Epoch 7/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1904 - accuracy: 0.4354 - val_loss: 1.1976 - val_accuracy: 0.4284\n",
            "Epoch 8/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1957 - accuracy: 0.4515 - val_loss: 1.1961 - val_accuracy: 0.4284\n",
            "Epoch 9/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1812 - accuracy: 0.4572 - val_loss: 1.1916 - val_accuracy: 0.4314\n",
            "Epoch 10/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1867 - accuracy: 0.4444 - val_loss: 1.1843 - val_accuracy: 0.4334\n",
            "Epoch 11/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1825 - accuracy: 0.4438 - val_loss: 1.1873 - val_accuracy: 0.4264\n",
            "Epoch 12/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1830 - accuracy: 0.4423 - val_loss: 1.1859 - val_accuracy: 0.4244\n",
            "Epoch 13/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1874 - accuracy: 0.4388 - val_loss: 1.1809 - val_accuracy: 0.4264\n",
            "Epoch 14/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1701 - accuracy: 0.4597 - val_loss: 1.1778 - val_accuracy: 0.4314\n",
            "Epoch 15/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1670 - accuracy: 0.4600 - val_loss: 1.1713 - val_accuracy: 0.4304\n",
            "Epoch 16/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1730 - accuracy: 0.4532 - val_loss: 1.1716 - val_accuracy: 0.4344\n",
            "Epoch 17/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1619 - accuracy: 0.4630 - val_loss: 1.1657 - val_accuracy: 0.4464\n",
            "Epoch 18/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1549 - accuracy: 0.4690 - val_loss: 1.1653 - val_accuracy: 0.4434\n",
            "Epoch 19/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1617 - accuracy: 0.4555 - val_loss: 1.1634 - val_accuracy: 0.4484\n",
            "Epoch 20/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1664 - accuracy: 0.4560 - val_loss: 1.1656 - val_accuracy: 0.4444\n",
            "Epoch 21/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1526 - accuracy: 0.4660 - val_loss: 1.1577 - val_accuracy: 0.4494\n",
            "Epoch 22/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1561 - accuracy: 0.4626 - val_loss: 1.1624 - val_accuracy: 0.4444\n",
            "Epoch 23/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1561 - accuracy: 0.4632 - val_loss: 1.1580 - val_accuracy: 0.4484\n",
            "Epoch 24/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1393 - accuracy: 0.4801 - val_loss: 1.1569 - val_accuracy: 0.4454\n",
            "Epoch 25/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1492 - accuracy: 0.4535 - val_loss: 1.1554 - val_accuracy: 0.4535\n",
            "Epoch 26/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1381 - accuracy: 0.4767 - val_loss: 1.1515 - val_accuracy: 0.4515\n",
            "Epoch 27/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1343 - accuracy: 0.4797 - val_loss: 1.1456 - val_accuracy: 0.4635\n",
            "Epoch 28/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1404 - accuracy: 0.4752 - val_loss: 1.1466 - val_accuracy: 0.4575\n",
            "Epoch 29/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1343 - accuracy: 0.4694 - val_loss: 1.1413 - val_accuracy: 0.4685\n",
            "Epoch 30/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1365 - accuracy: 0.4747 - val_loss: 1.1447 - val_accuracy: 0.4565\n",
            "Epoch 31/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1295 - accuracy: 0.4772 - val_loss: 1.1358 - val_accuracy: 0.4735\n",
            "Epoch 32/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1332 - accuracy: 0.4766 - val_loss: 1.1395 - val_accuracy: 0.4615\n",
            "Epoch 33/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1298 - accuracy: 0.4912 - val_loss: 1.1400 - val_accuracy: 0.4645\n",
            "Epoch 34/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1348 - accuracy: 0.4778 - val_loss: 1.1351 - val_accuracy: 0.4645\n",
            "Epoch 35/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1269 - accuracy: 0.4860 - val_loss: 1.1302 - val_accuracy: 0.4705\n",
            "Epoch 36/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1277 - accuracy: 0.4837 - val_loss: 1.1295 - val_accuracy: 0.4675\n",
            "Epoch 37/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1116 - accuracy: 0.4850 - val_loss: 1.1283 - val_accuracy: 0.4675\n",
            "Epoch 38/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1286 - accuracy: 0.4814 - val_loss: 1.1243 - val_accuracy: 0.4755\n",
            "Epoch 39/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1120 - accuracy: 0.4906 - val_loss: 1.1278 - val_accuracy: 0.4675\n",
            "Epoch 40/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1188 - accuracy: 0.4893 - val_loss: 1.1181 - val_accuracy: 0.4855\n",
            "Epoch 41/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1073 - accuracy: 0.4886 - val_loss: 1.1192 - val_accuracy: 0.4735\n",
            "Epoch 42/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1006 - accuracy: 0.5009 - val_loss: 1.1141 - val_accuracy: 0.4835\n",
            "Epoch 43/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1126 - accuracy: 0.4982 - val_loss: 1.1129 - val_accuracy: 0.4885\n",
            "Epoch 44/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1173 - accuracy: 0.4796 - val_loss: 1.1168 - val_accuracy: 0.4765\n",
            "Epoch 45/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.1184 - accuracy: 0.4965 - val_loss: 1.1146 - val_accuracy: 0.4795\n",
            "Epoch 46/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0951 - accuracy: 0.5065 - val_loss: 1.1157 - val_accuracy: 0.4795\n",
            "Epoch 47/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0896 - accuracy: 0.5140 - val_loss: 1.1088 - val_accuracy: 0.4925\n",
            "Epoch 48/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0987 - accuracy: 0.4979 - val_loss: 1.1079 - val_accuracy: 0.4915\n",
            "Epoch 49/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.1005 - accuracy: 0.4993 - val_loss: 1.1086 - val_accuracy: 0.4815\n",
            "Epoch 50/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0959 - accuracy: 0.5044 - val_loss: 1.1066 - val_accuracy: 0.4845\n",
            "Epoch 51/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0922 - accuracy: 0.5177 - val_loss: 1.1099 - val_accuracy: 0.4825\n",
            "Epoch 52/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0962 - accuracy: 0.5137 - val_loss: 1.1006 - val_accuracy: 0.4905\n",
            "Epoch 53/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0888 - accuracy: 0.5057 - val_loss: 1.1015 - val_accuracy: 0.4945\n",
            "Epoch 54/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0829 - accuracy: 0.5185 - val_loss: 1.0986 - val_accuracy: 0.4865\n",
            "Epoch 55/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0885 - accuracy: 0.5031 - val_loss: 1.0945 - val_accuracy: 0.4995\n",
            "Epoch 56/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0844 - accuracy: 0.5156 - val_loss: 1.0929 - val_accuracy: 0.4925\n",
            "Epoch 57/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 1.0835 - accuracy: 0.4983 - val_loss: 1.0921 - val_accuracy: 0.5025\n",
            "Epoch 58/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0783 - accuracy: 0.5072 - val_loss: 1.0823 - val_accuracy: 0.5035\n",
            "Epoch 59/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0591 - accuracy: 0.5199 - val_loss: 1.0819 - val_accuracy: 0.5115\n",
            "Epoch 60/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0848 - accuracy: 0.5102 - val_loss: 1.0832 - val_accuracy: 0.5035\n",
            "Epoch 61/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0851 - accuracy: 0.5087 - val_loss: 1.0830 - val_accuracy: 0.5065\n",
            "Epoch 62/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0770 - accuracy: 0.5123 - val_loss: 1.0823 - val_accuracy: 0.5095\n",
            "Epoch 63/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0692 - accuracy: 0.5172 - val_loss: 1.0746 - val_accuracy: 0.5185\n",
            "Epoch 64/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0705 - accuracy: 0.5143 - val_loss: 1.0853 - val_accuracy: 0.4985\n",
            "Epoch 65/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0707 - accuracy: 0.5151 - val_loss: 1.0785 - val_accuracy: 0.5145\n",
            "Epoch 66/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0699 - accuracy: 0.5201 - val_loss: 1.0765 - val_accuracy: 0.5115\n",
            "Epoch 67/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0682 - accuracy: 0.5294 - val_loss: 1.0710 - val_accuracy: 0.5135\n",
            "Epoch 68/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0489 - accuracy: 0.5330 - val_loss: 1.0684 - val_accuracy: 0.5225\n",
            "Epoch 69/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0561 - accuracy: 0.5273 - val_loss: 1.0674 - val_accuracy: 0.5045\n",
            "Epoch 70/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0551 - accuracy: 0.5257 - val_loss: 1.0667 - val_accuracy: 0.5145\n",
            "Epoch 71/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0538 - accuracy: 0.5316 - val_loss: 1.0608 - val_accuracy: 0.5165\n",
            "Epoch 72/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0627 - accuracy: 0.5256 - val_loss: 1.0632 - val_accuracy: 0.5135\n",
            "Epoch 73/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0625 - accuracy: 0.5263 - val_loss: 1.0560 - val_accuracy: 0.5225\n",
            "Epoch 74/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0511 - accuracy: 0.5303 - val_loss: 1.0587 - val_accuracy: 0.5185\n",
            "Epoch 75/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0514 - accuracy: 0.5311 - val_loss: 1.0605 - val_accuracy: 0.5145\n",
            "Epoch 76/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0418 - accuracy: 0.5294 - val_loss: 1.0524 - val_accuracy: 0.5185\n",
            "Epoch 77/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0362 - accuracy: 0.5412 - val_loss: 1.0472 - val_accuracy: 0.5245\n",
            "Epoch 78/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0584 - accuracy: 0.5310 - val_loss: 1.0450 - val_accuracy: 0.5255\n",
            "Epoch 79/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0528 - accuracy: 0.5264 - val_loss: 1.0426 - val_accuracy: 0.5295\n",
            "Epoch 80/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0506 - accuracy: 0.5248 - val_loss: 1.0395 - val_accuracy: 0.5285\n",
            "Epoch 81/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0533 - accuracy: 0.5391 - val_loss: 1.0410 - val_accuracy: 0.5285\n",
            "Epoch 82/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0256 - accuracy: 0.5560 - val_loss: 1.0391 - val_accuracy: 0.5285\n",
            "Epoch 83/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0333 - accuracy: 0.5340 - val_loss: 1.0411 - val_accuracy: 0.5225\n",
            "Epoch 84/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 1.0201 - accuracy: 0.5479 - val_loss: 1.0394 - val_accuracy: 0.5185\n",
            "Epoch 85/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0324 - accuracy: 0.5371 - val_loss: 1.0380 - val_accuracy: 0.5225\n",
            "Epoch 86/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0275 - accuracy: 0.5542 - val_loss: 1.0293 - val_accuracy: 0.5415\n",
            "Epoch 87/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0186 - accuracy: 0.5570 - val_loss: 1.0324 - val_accuracy: 0.5325\n",
            "Epoch 88/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0162 - accuracy: 0.5430 - val_loss: 1.0335 - val_accuracy: 0.5255\n",
            "Epoch 89/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0233 - accuracy: 0.5482 - val_loss: 1.0296 - val_accuracy: 0.5315\n",
            "Epoch 90/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0215 - accuracy: 0.5396 - val_loss: 1.0318 - val_accuracy: 0.5295\n",
            "Epoch 91/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0344 - accuracy: 0.5395 - val_loss: 1.0247 - val_accuracy: 0.5405\n",
            "Epoch 92/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0014 - accuracy: 0.5618 - val_loss: 1.0319 - val_accuracy: 0.5305\n",
            "Epoch 93/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0193 - accuracy: 0.5420 - val_loss: 1.0170 - val_accuracy: 0.5405\n",
            "Epoch 94/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0052 - accuracy: 0.5543 - val_loss: 1.0127 - val_accuracy: 0.5455\n",
            "Epoch 95/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0157 - accuracy: 0.5505 - val_loss: 1.0106 - val_accuracy: 0.5455\n",
            "Epoch 96/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0132 - accuracy: 0.5574 - val_loss: 1.0189 - val_accuracy: 0.5395\n",
            "Epoch 97/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9810 - accuracy: 0.5707 - val_loss: 1.0184 - val_accuracy: 0.5365\n",
            "Epoch 98/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0224 - accuracy: 0.5480 - val_loss: 1.0092 - val_accuracy: 0.5455\n",
            "Epoch 99/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0065 - accuracy: 0.5533 - val_loss: 1.0105 - val_accuracy: 0.5475\n",
            "Epoch 100/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0072 - accuracy: 0.5660 - val_loss: 1.0124 - val_accuracy: 0.5485\n",
            "Epoch 101/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9940 - accuracy: 0.5581 - val_loss: 1.0028 - val_accuracy: 0.5506\n",
            "Epoch 102/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.9981 - accuracy: 0.5523 - val_loss: 1.0042 - val_accuracy: 0.5516\n",
            "Epoch 103/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9944 - accuracy: 0.5617 - val_loss: 0.9982 - val_accuracy: 0.5516\n",
            "Epoch 104/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 1.0027 - accuracy: 0.5638 - val_loss: 1.0003 - val_accuracy: 0.5576\n",
            "Epoch 105/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9927 - accuracy: 0.5589 - val_loss: 1.0049 - val_accuracy: 0.5415\n",
            "Epoch 106/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9937 - accuracy: 0.5604 - val_loss: 1.0039 - val_accuracy: 0.5516\n",
            "Epoch 107/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9900 - accuracy: 0.5698 - val_loss: 0.9974 - val_accuracy: 0.5506\n",
            "Epoch 108/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.9900 - accuracy: 0.5619 - val_loss: 0.9933 - val_accuracy: 0.5536\n",
            "Epoch 109/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9970 - accuracy: 0.5635 - val_loss: 1.0033 - val_accuracy: 0.5526\n",
            "Epoch 110/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9885 - accuracy: 0.5659 - val_loss: 0.9958 - val_accuracy: 0.5516\n",
            "Epoch 111/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.9806 - accuracy: 0.5723 - val_loss: 0.9859 - val_accuracy: 0.5586\n",
            "Epoch 112/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9834 - accuracy: 0.5707 - val_loss: 0.9931 - val_accuracy: 0.5516\n",
            "Epoch 113/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9770 - accuracy: 0.5582 - val_loss: 0.9860 - val_accuracy: 0.5586\n",
            "Epoch 114/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9680 - accuracy: 0.5727 - val_loss: 0.9842 - val_accuracy: 0.5576\n",
            "Epoch 115/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9802 - accuracy: 0.5700 - val_loss: 0.9913 - val_accuracy: 0.5596\n",
            "Epoch 116/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9559 - accuracy: 0.5785 - val_loss: 0.9830 - val_accuracy: 0.5676\n",
            "Epoch 117/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9708 - accuracy: 0.5686 - val_loss: 0.9802 - val_accuracy: 0.5556\n",
            "Epoch 118/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9616 - accuracy: 0.5798 - val_loss: 0.9761 - val_accuracy: 0.5676\n",
            "Epoch 119/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9613 - accuracy: 0.5765 - val_loss: 0.9738 - val_accuracy: 0.5646\n",
            "Epoch 120/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9670 - accuracy: 0.5742 - val_loss: 0.9748 - val_accuracy: 0.5776\n",
            "Epoch 121/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9523 - accuracy: 0.5823 - val_loss: 0.9764 - val_accuracy: 0.5706\n",
            "Epoch 122/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9602 - accuracy: 0.5804 - val_loss: 0.9733 - val_accuracy: 0.5736\n",
            "Epoch 123/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9612 - accuracy: 0.5771 - val_loss: 0.9797 - val_accuracy: 0.5616\n",
            "Epoch 124/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9584 - accuracy: 0.5804 - val_loss: 0.9743 - val_accuracy: 0.5686\n",
            "Epoch 125/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9567 - accuracy: 0.5745 - val_loss: 0.9680 - val_accuracy: 0.5626\n",
            "Epoch 126/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9528 - accuracy: 0.5879 - val_loss: 0.9685 - val_accuracy: 0.5726\n",
            "Epoch 127/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.9439 - accuracy: 0.5995 - val_loss: 0.9768 - val_accuracy: 0.5706\n",
            "Epoch 128/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9695 - accuracy: 0.5728 - val_loss: 0.9758 - val_accuracy: 0.5706\n",
            "Epoch 129/300\n",
            "63/63 [==============================] - 0s 2ms/step - loss: 0.9565 - accuracy: 0.5881 - val_loss: 0.9699 - val_accuracy: 0.5776\n",
            "Epoch 130/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.5882 - val_loss: 0.9595 - val_accuracy: 0.5776\n",
            "Epoch 131/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9391 - accuracy: 0.5866 - val_loss: 0.9639 - val_accuracy: 0.5756\n",
            "Epoch 132/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9531 - accuracy: 0.5761 - val_loss: 0.9663 - val_accuracy: 0.5726\n",
            "Epoch 133/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9426 - accuracy: 0.6002 - val_loss: 0.9581 - val_accuracy: 0.5766\n",
            "Epoch 134/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9533 - accuracy: 0.5852 - val_loss: 0.9677 - val_accuracy: 0.5736\n",
            "Epoch 135/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.5971 - val_loss: 0.9706 - val_accuracy: 0.5796\n",
            "Epoch 136/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9374 - accuracy: 0.6011 - val_loss: 0.9613 - val_accuracy: 0.5716\n",
            "Epoch 137/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9434 - accuracy: 0.5887 - val_loss: 0.9530 - val_accuracy: 0.5816\n",
            "Epoch 138/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9169 - accuracy: 0.6008 - val_loss: 0.9599 - val_accuracy: 0.5736\n",
            "Epoch 139/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9288 - accuracy: 0.5989 - val_loss: 0.9605 - val_accuracy: 0.5726\n",
            "Epoch 140/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9351 - accuracy: 0.5893 - val_loss: 0.9640 - val_accuracy: 0.5746\n",
            "Epoch 141/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9495 - accuracy: 0.5879 - val_loss: 0.9524 - val_accuracy: 0.5836\n",
            "Epoch 142/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9238 - accuracy: 0.5956 - val_loss: 0.9495 - val_accuracy: 0.5706\n",
            "Epoch 143/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9368 - accuracy: 0.5861 - val_loss: 0.9470 - val_accuracy: 0.5886\n",
            "Epoch 144/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.9316 - accuracy: 0.6025 - val_loss: 0.9556 - val_accuracy: 0.5706\n",
            "Epoch 145/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9163 - accuracy: 0.6042 - val_loss: 0.9402 - val_accuracy: 0.5846\n",
            "Epoch 146/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9249 - accuracy: 0.5971 - val_loss: 0.9473 - val_accuracy: 0.5736\n",
            "Epoch 147/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9153 - accuracy: 0.6089 - val_loss: 0.9432 - val_accuracy: 0.5696\n",
            "Epoch 148/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9209 - accuracy: 0.6020 - val_loss: 0.9487 - val_accuracy: 0.5756\n",
            "Epoch 149/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8998 - accuracy: 0.6105 - val_loss: 0.9412 - val_accuracy: 0.5746\n",
            "Epoch 150/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.6063 - val_loss: 0.9433 - val_accuracy: 0.5766\n",
            "Epoch 151/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9165 - accuracy: 0.6044 - val_loss: 0.9598 - val_accuracy: 0.5736\n",
            "Epoch 152/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9139 - accuracy: 0.5955 - val_loss: 0.9463 - val_accuracy: 0.5766\n",
            "Epoch 153/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9215 - accuracy: 0.6033 - val_loss: 0.9488 - val_accuracy: 0.5776\n",
            "Epoch 154/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9018 - accuracy: 0.6047 - val_loss: 0.9320 - val_accuracy: 0.5826\n",
            "Epoch 155/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8955 - accuracy: 0.6107 - val_loss: 0.9321 - val_accuracy: 0.5846\n",
            "Epoch 156/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9115 - accuracy: 0.6083 - val_loss: 0.9383 - val_accuracy: 0.5786\n",
            "Epoch 157/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9090 - accuracy: 0.6059 - val_loss: 0.9375 - val_accuracy: 0.5846\n",
            "Epoch 158/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9048 - accuracy: 0.6109 - val_loss: 0.9482 - val_accuracy: 0.5686\n",
            "Epoch 159/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9094 - accuracy: 0.6043 - val_loss: 0.9330 - val_accuracy: 0.5846\n",
            "Epoch 160/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8940 - accuracy: 0.6097 - val_loss: 0.9378 - val_accuracy: 0.5826\n",
            "Epoch 161/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9066 - accuracy: 0.6161 - val_loss: 0.9342 - val_accuracy: 0.5866\n",
            "Epoch 162/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9059 - accuracy: 0.6103 - val_loss: 0.9297 - val_accuracy: 0.5816\n",
            "Epoch 163/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8791 - accuracy: 0.6269 - val_loss: 0.9300 - val_accuracy: 0.5976\n",
            "Epoch 164/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8973 - accuracy: 0.6185 - val_loss: 0.9286 - val_accuracy: 0.5966\n",
            "Epoch 165/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8798 - accuracy: 0.6263 - val_loss: 0.9336 - val_accuracy: 0.5876\n",
            "Epoch 166/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8872 - accuracy: 0.6254 - val_loss: 0.9364 - val_accuracy: 0.5926\n",
            "Epoch 167/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9007 - accuracy: 0.6120 - val_loss: 0.9424 - val_accuracy: 0.5866\n",
            "Epoch 168/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8948 - accuracy: 0.6158 - val_loss: 0.9337 - val_accuracy: 0.5866\n",
            "Epoch 169/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8897 - accuracy: 0.6157 - val_loss: 0.9428 - val_accuracy: 0.5836\n",
            "Epoch 170/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8828 - accuracy: 0.6221 - val_loss: 0.9299 - val_accuracy: 0.5826\n",
            "Epoch 171/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.6160 - val_loss: 0.9378 - val_accuracy: 0.5746\n",
            "Epoch 172/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8942 - accuracy: 0.6173 - val_loss: 0.9273 - val_accuracy: 0.5856\n",
            "Epoch 173/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.9061 - accuracy: 0.6077 - val_loss: 0.9395 - val_accuracy: 0.5866\n",
            "Epoch 174/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8706 - accuracy: 0.6241 - val_loss: 0.9260 - val_accuracy: 0.5906\n",
            "Epoch 175/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8848 - accuracy: 0.6252 - val_loss: 0.9293 - val_accuracy: 0.5816\n",
            "Epoch 176/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8965 - accuracy: 0.6240 - val_loss: 0.9341 - val_accuracy: 0.5906\n",
            "Epoch 177/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8799 - accuracy: 0.6237 - val_loss: 0.9293 - val_accuracy: 0.5926\n",
            "Epoch 178/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8822 - accuracy: 0.6209 - val_loss: 0.9270 - val_accuracy: 0.5886\n",
            "Epoch 179/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8854 - accuracy: 0.6196 - val_loss: 0.9299 - val_accuracy: 0.5916\n",
            "Epoch 180/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8800 - accuracy: 0.6239 - val_loss: 0.9219 - val_accuracy: 0.5856\n",
            "Epoch 181/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8795 - accuracy: 0.6216 - val_loss: 0.9124 - val_accuracy: 0.5926\n",
            "Epoch 182/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8609 - accuracy: 0.6323 - val_loss: 0.9258 - val_accuracy: 0.5926\n",
            "Epoch 183/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8748 - accuracy: 0.6233 - val_loss: 0.9207 - val_accuracy: 0.5976\n",
            "Epoch 184/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8721 - accuracy: 0.6376 - val_loss: 0.9222 - val_accuracy: 0.5976\n",
            "Epoch 185/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8722 - accuracy: 0.6253 - val_loss: 0.9201 - val_accuracy: 0.6056\n",
            "Epoch 186/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8830 - accuracy: 0.6171 - val_loss: 0.9289 - val_accuracy: 0.5996\n",
            "Epoch 187/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8760 - accuracy: 0.6203 - val_loss: 0.9190 - val_accuracy: 0.6096\n",
            "Epoch 188/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8723 - accuracy: 0.6269 - val_loss: 0.9286 - val_accuracy: 0.5996\n",
            "Epoch 189/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8562 - accuracy: 0.6270 - val_loss: 0.9302 - val_accuracy: 0.6036\n",
            "Epoch 190/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8654 - accuracy: 0.6173 - val_loss: 0.9270 - val_accuracy: 0.5936\n",
            "Epoch 191/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8616 - accuracy: 0.6225 - val_loss: 0.9204 - val_accuracy: 0.6026\n",
            "Epoch 192/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8687 - accuracy: 0.6291 - val_loss: 0.9199 - val_accuracy: 0.5896\n",
            "Epoch 193/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8487 - accuracy: 0.6400 - val_loss: 0.9315 - val_accuracy: 0.5946\n",
            "Epoch 194/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8663 - accuracy: 0.6351 - val_loss: 0.9248 - val_accuracy: 0.5986\n",
            "Epoch 195/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8542 - accuracy: 0.6357 - val_loss: 0.9197 - val_accuracy: 0.5926\n",
            "Epoch 196/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8445 - accuracy: 0.6373 - val_loss: 0.9277 - val_accuracy: 0.5906\n",
            "Epoch 197/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8627 - accuracy: 0.6329 - val_loss: 0.9109 - val_accuracy: 0.5946\n",
            "Epoch 198/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8471 - accuracy: 0.6443 - val_loss: 0.9168 - val_accuracy: 0.6016\n",
            "Epoch 199/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8408 - accuracy: 0.6436 - val_loss: 0.9266 - val_accuracy: 0.5906\n",
            "Epoch 200/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8454 - accuracy: 0.6387 - val_loss: 0.9068 - val_accuracy: 0.6016\n",
            "Epoch 201/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8486 - accuracy: 0.6312 - val_loss: 0.9177 - val_accuracy: 0.6006\n",
            "Epoch 202/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8616 - accuracy: 0.6258 - val_loss: 0.9287 - val_accuracy: 0.6036\n",
            "Epoch 203/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8515 - accuracy: 0.6382 - val_loss: 0.9233 - val_accuracy: 0.5996\n",
            "Epoch 204/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8524 - accuracy: 0.6285 - val_loss: 0.9260 - val_accuracy: 0.5986\n",
            "Epoch 205/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8489 - accuracy: 0.6455 - val_loss: 0.9138 - val_accuracy: 0.5996\n",
            "Epoch 206/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8568 - accuracy: 0.6418 - val_loss: 0.9155 - val_accuracy: 0.6136\n",
            "Epoch 207/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8440 - accuracy: 0.6369 - val_loss: 0.9215 - val_accuracy: 0.5886\n",
            "Epoch 208/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8415 - accuracy: 0.6490 - val_loss: 0.9231 - val_accuracy: 0.6016\n",
            "Epoch 209/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8549 - accuracy: 0.6322 - val_loss: 0.9189 - val_accuracy: 0.6046\n",
            "Epoch 210/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8597 - accuracy: 0.6379 - val_loss: 0.9090 - val_accuracy: 0.6126\n",
            "Epoch 211/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8586 - accuracy: 0.6448 - val_loss: 0.9255 - val_accuracy: 0.6026\n",
            "Epoch 212/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8499 - accuracy: 0.6415 - val_loss: 0.9126 - val_accuracy: 0.6046\n",
            "Epoch 213/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8436 - accuracy: 0.6384 - val_loss: 0.9197 - val_accuracy: 0.6036\n",
            "Epoch 214/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.6515 - val_loss: 0.9147 - val_accuracy: 0.6106\n",
            "Epoch 215/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8383 - accuracy: 0.6423 - val_loss: 0.9281 - val_accuracy: 0.5986\n",
            "Epoch 216/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8269 - accuracy: 0.6430 - val_loss: 0.9174 - val_accuracy: 0.6106\n",
            "Epoch 217/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8422 - accuracy: 0.6360 - val_loss: 0.9098 - val_accuracy: 0.6086\n",
            "Epoch 218/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8392 - accuracy: 0.6437 - val_loss: 0.9138 - val_accuracy: 0.5996\n",
            "Epoch 219/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8363 - accuracy: 0.6389 - val_loss: 0.9092 - val_accuracy: 0.5946\n",
            "Epoch 220/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8260 - accuracy: 0.6497 - val_loss: 0.9125 - val_accuracy: 0.6056\n",
            "Epoch 221/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8435 - accuracy: 0.6390 - val_loss: 0.9095 - val_accuracy: 0.6026\n",
            "Epoch 222/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8448 - accuracy: 0.6431 - val_loss: 0.9120 - val_accuracy: 0.6096\n",
            "Epoch 223/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8470 - accuracy: 0.6485 - val_loss: 0.9108 - val_accuracy: 0.6046\n",
            "Epoch 224/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8258 - accuracy: 0.6447 - val_loss: 0.9145 - val_accuracy: 0.6056\n",
            "Epoch 225/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8176 - accuracy: 0.6518 - val_loss: 0.9187 - val_accuracy: 0.5996\n",
            "Epoch 226/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8347 - accuracy: 0.6592 - val_loss: 0.8979 - val_accuracy: 0.6286\n",
            "Epoch 227/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8424 - accuracy: 0.6407 - val_loss: 0.9103 - val_accuracy: 0.6056\n",
            "Epoch 228/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8214 - accuracy: 0.6469 - val_loss: 0.9049 - val_accuracy: 0.6156\n",
            "Epoch 229/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6583 - val_loss: 0.9049 - val_accuracy: 0.6106\n",
            "Epoch 230/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8305 - accuracy: 0.6490 - val_loss: 0.9051 - val_accuracy: 0.6136\n",
            "Epoch 231/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8307 - accuracy: 0.6416 - val_loss: 0.9085 - val_accuracy: 0.6046\n",
            "Epoch 232/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8296 - accuracy: 0.6468 - val_loss: 0.8966 - val_accuracy: 0.6006\n",
            "Epoch 233/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8342 - accuracy: 0.6420 - val_loss: 0.9150 - val_accuracy: 0.6096\n",
            "Epoch 234/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8251 - accuracy: 0.6390 - val_loss: 0.9112 - val_accuracy: 0.6086\n",
            "Epoch 235/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8276 - accuracy: 0.6422 - val_loss: 0.9052 - val_accuracy: 0.6016\n",
            "Epoch 236/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8285 - accuracy: 0.6544 - val_loss: 0.8997 - val_accuracy: 0.6156\n",
            "Epoch 237/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8164 - accuracy: 0.6550 - val_loss: 0.8975 - val_accuracy: 0.6106\n",
            "Epoch 238/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8064 - accuracy: 0.6546 - val_loss: 0.9003 - val_accuracy: 0.6116\n",
            "Epoch 239/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8180 - accuracy: 0.6493 - val_loss: 0.9027 - val_accuracy: 0.6236\n",
            "Epoch 240/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8201 - accuracy: 0.6518 - val_loss: 0.8946 - val_accuracy: 0.6226\n",
            "Epoch 241/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8133 - accuracy: 0.6518 - val_loss: 0.8975 - val_accuracy: 0.6116\n",
            "Epoch 242/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8193 - accuracy: 0.6518 - val_loss: 0.8973 - val_accuracy: 0.6286\n",
            "Epoch 243/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8070 - accuracy: 0.6601 - val_loss: 0.8998 - val_accuracy: 0.6186\n",
            "Epoch 244/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8223 - accuracy: 0.6596 - val_loss: 0.8968 - val_accuracy: 0.6246\n",
            "Epoch 245/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8050 - accuracy: 0.6582 - val_loss: 0.8971 - val_accuracy: 0.6156\n",
            "Epoch 246/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8262 - accuracy: 0.6458 - val_loss: 0.9026 - val_accuracy: 0.6096\n",
            "Epoch 247/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8143 - accuracy: 0.6547 - val_loss: 0.8945 - val_accuracy: 0.6206\n",
            "Epoch 248/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8023 - accuracy: 0.6610 - val_loss: 0.8863 - val_accuracy: 0.6226\n",
            "Epoch 249/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8180 - accuracy: 0.6571 - val_loss: 0.8856 - val_accuracy: 0.6246\n",
            "Epoch 250/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8289 - accuracy: 0.6464 - val_loss: 0.9017 - val_accuracy: 0.6136\n",
            "Epoch 251/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8005 - accuracy: 0.6628 - val_loss: 0.9099 - val_accuracy: 0.6006\n",
            "Epoch 252/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8056 - accuracy: 0.6604 - val_loss: 0.8923 - val_accuracy: 0.6196\n",
            "Epoch 253/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8084 - accuracy: 0.6630 - val_loss: 0.8974 - val_accuracy: 0.6066\n",
            "Epoch 254/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8161 - accuracy: 0.6556 - val_loss: 0.8917 - val_accuracy: 0.6186\n",
            "Epoch 255/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8186 - accuracy: 0.6618 - val_loss: 0.8921 - val_accuracy: 0.6206\n",
            "Epoch 256/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8086 - accuracy: 0.6637 - val_loss: 0.8794 - val_accuracy: 0.6386\n",
            "Epoch 257/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8112 - accuracy: 0.6545 - val_loss: 0.8983 - val_accuracy: 0.6146\n",
            "Epoch 258/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8099 - accuracy: 0.6543 - val_loss: 0.8927 - val_accuracy: 0.6266\n",
            "Epoch 259/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7909 - accuracy: 0.6710 - val_loss: 0.9040 - val_accuracy: 0.6256\n",
            "Epoch 260/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7874 - accuracy: 0.6648 - val_loss: 0.8870 - val_accuracy: 0.6296\n",
            "Epoch 261/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7964 - accuracy: 0.6653 - val_loss: 0.9060 - val_accuracy: 0.6206\n",
            "Epoch 262/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8081 - accuracy: 0.6586 - val_loss: 0.8937 - val_accuracy: 0.6306\n",
            "Epoch 263/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8145 - accuracy: 0.6511 - val_loss: 0.9041 - val_accuracy: 0.6166\n",
            "Epoch 264/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7893 - accuracy: 0.6723 - val_loss: 0.9029 - val_accuracy: 0.6206\n",
            "Epoch 265/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8121 - accuracy: 0.6661 - val_loss: 0.8958 - val_accuracy: 0.6166\n",
            "Epoch 266/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7958 - accuracy: 0.6676 - val_loss: 0.9049 - val_accuracy: 0.6196\n",
            "Epoch 267/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8019 - accuracy: 0.6542 - val_loss: 0.9032 - val_accuracy: 0.6226\n",
            "Epoch 268/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8320 - accuracy: 0.6502 - val_loss: 0.8957 - val_accuracy: 0.6186\n",
            "Epoch 269/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8003 - accuracy: 0.6609 - val_loss: 0.8890 - val_accuracy: 0.6136\n",
            "Epoch 270/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8042 - accuracy: 0.6559 - val_loss: 0.8992 - val_accuracy: 0.6206\n",
            "Epoch 271/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8039 - accuracy: 0.6648 - val_loss: 0.8915 - val_accuracy: 0.6146\n",
            "Epoch 272/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7937 - accuracy: 0.6698 - val_loss: 0.8828 - val_accuracy: 0.6206\n",
            "Epoch 273/300\n",
            "63/63 [==============================] - 0s 4ms/step - loss: 0.8124 - accuracy: 0.6617 - val_loss: 0.8991 - val_accuracy: 0.6226\n",
            "Epoch 274/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8125 - accuracy: 0.6551 - val_loss: 0.8905 - val_accuracy: 0.6236\n",
            "Epoch 275/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8090 - accuracy: 0.6520 - val_loss: 0.8832 - val_accuracy: 0.6416\n",
            "Epoch 276/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8061 - accuracy: 0.6615 - val_loss: 0.9055 - val_accuracy: 0.6246\n",
            "Epoch 277/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8118 - accuracy: 0.6521 - val_loss: 0.8832 - val_accuracy: 0.6306\n",
            "Epoch 278/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.6606 - val_loss: 0.8815 - val_accuracy: 0.6196\n",
            "Epoch 279/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7987 - accuracy: 0.6729 - val_loss: 0.8878 - val_accuracy: 0.6296\n",
            "Epoch 280/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7932 - accuracy: 0.6741 - val_loss: 0.8835 - val_accuracy: 0.6316\n",
            "Epoch 281/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7735 - accuracy: 0.6723 - val_loss: 0.8838 - val_accuracy: 0.6156\n",
            "Epoch 282/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7953 - accuracy: 0.6606 - val_loss: 0.8868 - val_accuracy: 0.6286\n",
            "Epoch 283/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7866 - accuracy: 0.6685 - val_loss: 0.8891 - val_accuracy: 0.6366\n",
            "Epoch 284/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.8182 - accuracy: 0.6572 - val_loss: 0.8891 - val_accuracy: 0.6286\n",
            "Epoch 285/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7935 - accuracy: 0.6736 - val_loss: 0.8886 - val_accuracy: 0.6336\n",
            "Epoch 286/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7969 - accuracy: 0.6711 - val_loss: 0.8880 - val_accuracy: 0.6196\n",
            "Epoch 287/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7808 - accuracy: 0.6779 - val_loss: 0.8832 - val_accuracy: 0.6256\n",
            "Epoch 288/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7926 - accuracy: 0.6745 - val_loss: 0.8977 - val_accuracy: 0.6246\n",
            "Epoch 289/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7799 - accuracy: 0.6751 - val_loss: 0.8966 - val_accuracy: 0.6256\n",
            "Epoch 290/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7827 - accuracy: 0.6722 - val_loss: 0.8879 - val_accuracy: 0.6276\n",
            "Epoch 291/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7903 - accuracy: 0.6712 - val_loss: 0.8912 - val_accuracy: 0.6266\n",
            "Epoch 292/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7979 - accuracy: 0.6643 - val_loss: 0.9042 - val_accuracy: 0.6306\n",
            "Epoch 293/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7902 - accuracy: 0.6713 - val_loss: 0.8884 - val_accuracy: 0.6276\n",
            "Epoch 294/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6634 - val_loss: 0.8917 - val_accuracy: 0.6316\n",
            "Epoch 295/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7890 - accuracy: 0.6583 - val_loss: 0.8910 - val_accuracy: 0.6306\n",
            "Epoch 296/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7731 - accuracy: 0.6673 - val_loss: 0.8977 - val_accuracy: 0.6356\n",
            "Epoch 297/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7972 - accuracy: 0.6747 - val_loss: 0.8871 - val_accuracy: 0.6416\n",
            "Epoch 298/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7823 - accuracy: 0.6687 - val_loss: 0.8939 - val_accuracy: 0.6346\n",
            "Epoch 299/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7913 - accuracy: 0.6767 - val_loss: 0.8855 - val_accuracy: 0.6366\n",
            "Epoch 300/300\n",
            "63/63 [==============================] - 0s 3ms/step - loss: 0.7935 - accuracy: 0.6621 - val_loss: 0.8927 - val_accuracy: 0.6356\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xzvMo-m9EyA6",
        "outputId": "ef614c10-0bd2-411d-d535-8eb6d6a2e881"
      },
      "source": [
        "test_loss, test_acc  = model.evaluate(X_test, y_test, batch_size=128)\r\n",
        "print(\"The test loss is :\",test_loss, \"\\nThe test accuracy is :\",test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.8229 - accuracy: 0.6517\n",
            "The test loss is : 0.822942852973938 \n",
            "The test accuracy is : 0.6516516804695129\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "M1815y3TEy9E",
        "outputId": "df2ad661-1980-4dc9-966e-8fd529ed2745"
      },
      "source": [
        "N = 300\r\n",
        "plt.style.use(\"ggplot\")\r\n",
        "plt.figure()\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"loss\"], label=\"train_loss\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"val_loss\"], label=\"val_loss\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"accuracy\"], label=\"train_acc\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "plt.title(\"Training Loss and Accuracy on Music Dataset\")\r\n",
        "plt.xlabel(\"Epoch #\")\r\n",
        "plt.ylabel(\"Loss/Accuracy\")\r\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7fea94570c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}