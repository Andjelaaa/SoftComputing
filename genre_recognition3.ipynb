{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import h5py\n",
    "import librosa\n",
    "import itertools\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility purposes\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to split a song into multiple songs using overlapping windows\n",
    "\"\"\"\n",
    "def splitsongs(X, y, window = 0.05, overlap = 0.5):\n",
    "    # Empty lists to hold our results\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "\n",
    "    # Get the input song array size\n",
    "    xshape = X.shape[0]\n",
    "    chunk = int(xshape*window)\n",
    "    offset = int(chunk*(1.-overlap))\n",
    "    \n",
    "    # Split the song and create new ones on windows\n",
    "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
    "    for s in spsong:\n",
    "        if s.shape[0] != chunk:\n",
    "            continue\n",
    "\n",
    "        temp_X.append(s)\n",
    "        temp_y.append(y)\n",
    "\n",
    "    return np.array(temp_X), np.array(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to convert a list of songs to a np array of melspectrograms\n",
    "\"\"\"\n",
    "def to_melspectrogram(songs, n_fft=1024, hop_length=256):\n",
    "    # Transformation function\n",
    "    melspec = lambda x: librosa.feature.melspectrogram(x, n_fft=n_fft,\n",
    "        hop_length=hop_length, n_mels=128)[:,:,np.newaxis]\n",
    "\n",
    "    # map transformation of input songs to melspectrogram using log-scale\n",
    "    tsongs = map(melspec, songs)\n",
    "    # np.array([librosa.power_to_db(s, ref=np.max) for s in list(tsongs)])\n",
    "    return np.array(list(tsongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_convert(X, y):\n",
    "    arr_specs, arr_genres = [], []\n",
    "    \n",
    "    # Convert to spectrograms and split into small windows\n",
    "    for fn, genre in zip(X, y):\n",
    "        signal, sr = librosa.load(fn)\n",
    "        signal = signal[:song_samples]\n",
    "\n",
    "        # Convert to dataset of spectograms/melspectograms\n",
    "        signals, y = splitsongs(signal, genre)\n",
    "\n",
    "        # Convert to \"spec\" representation\n",
    "        specs = to_melspectrogram(signals)\n",
    "\n",
    "        # Save files\n",
    "        arr_genres.extend(y)\n",
    "        arr_specs.extend(specs)\n",
    "    \n",
    "    return np.array(arr_specs), to_categorical(arr_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(src_dir, genres, song_samples):    \n",
    "    # Empty array of dicts with the processed features from all files\n",
    "    arr_fn = []\n",
    "    arr_genres = []\n",
    "\n",
    "    # Get file list from the folders\n",
    "    for x,_ in genres.items():\n",
    "        folder = src_dir + x\n",
    "        for root, subdirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_name = folder + \"/\" + file\n",
    "\n",
    "                # Save the file name and the genre\n",
    "                arr_fn.append(file_name)\n",
    "                arr_genres.append(genres[x])\n",
    "    \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        arr_fn, arr_genres, test_size=0.3, random_state=42, stratify=arr_genres\n",
    "    )\n",
    "    \n",
    "    # Split into small segments and convert to spectrogram\n",
    "    X_train, y_train = split_convert(X_train, y_train)\n",
    "    X_test, y_test = split_convert(X_test, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gtzan_dir = 'Data/genres_original/'\n",
    "song_samples = 660000\n",
    "genres = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4, \n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}\n",
    "\n",
    "# Read the data\n",
    "X_train, X_test, y_train, y_test = read_data(gtzan_dir, genres, song_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27300, 128, 129, 1) (11700, 128, 129, 1) (27300, 10) (11700, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class GTZANGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size=64, is_test = False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indexes\n",
    "        signals = self.X[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Apply data augmentation\n",
    "        if not self.is_test:\n",
    "            signals = self.__augment(signals)\n",
    "        return signals, self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "    \n",
    "    def __augment(self, signals, hor_flip = 0.5, random_cutout = 0.5):\n",
    "        spectrograms =  []\n",
    "        for s in signals:\n",
    "            signal = copy(s)\n",
    "            \n",
    "            # Perform horizontal flip\n",
    "            if np.random.rand() < hor_flip:\n",
    "                signal = np.flip(signal, 1)\n",
    "\n",
    "            # Perform random cutoout of some frequency/time\n",
    "            if np.random.rand() < random_cutout:\n",
    "                lines = np.random.randint(signal.shape[0], size=3)\n",
    "                cols = np.random.randint(signal.shape[0], size=4)\n",
    "                signal[lines, :, :] = -80 # dB\n",
    "                signal[:, cols, :] = -80 # dB\n",
    "\n",
    "            spectrograms.append(signal)\n",
    "        return np.array(spectrograms)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_filters, pool_size=(2, 2)):\n",
    "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size, strides=pool_size)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "def create_model(input_shape, num_genres):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = conv_block(inpt, 16)\n",
    "    x = conv_block(x, 32)\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256)\n",
    "    \n",
    "    # Global Pooling and MLP\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu', \n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    predictions = Dense(num_genres, \n",
    "                        activation='softmax', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    \n",
    "    model = Model(inputs=inpt, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train[0].shape, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 128, 129, 1)       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 129, 16)      160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 129, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,495,114\n",
      "Trainable params: 2,495,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.95,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=2,\n",
    "    min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "batch_size = 128\n",
    "train_generator = GTZANGenerator(X_train, y_train)\n",
    "steps_per_epoch = np.ceil(len(X_train)/batch_size)\n",
    "\n",
    "validation_generator = GTZANGenerator(X_test, y_test)\n",
    "val_steps = np.ceil(len(X_test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "214/214 [==============================] - 499s 2s/step - loss: 6.9510 - acc: 0.1389 - val_loss: 2.9836 - val_acc: 0.1892\n",
      "Epoch 2/150\n",
      "214/214 [==============================] - 519s 2s/step - loss: 2.5916 - acc: 0.1627 - val_loss: 2.3645 - val_acc: 0.2391\n",
      "Epoch 3/150\n",
      "214/214 [==============================] - 503s 2s/step - loss: 2.3053 - acc: 0.1844 - val_loss: 2.1558 - val_acc: 0.2147\n",
      "Epoch 4/150\n",
      "214/214 [==============================] - 466s 2s/step - loss: 2.1937 - acc: 0.1837 - val_loss: 2.0687 - val_acc: 0.1906\n",
      "Epoch 5/150\n",
      "214/214 [==============================] - 394s 2s/step - loss: 2.1431 - acc: 0.2149 - val_loss: 2.0422 - val_acc: 0.1997\n",
      "Epoch 6/150\n",
      "214/214 [==============================] - 420s 2s/step - loss: 2.1037 - acc: 0.2136 - val_loss: 2.0366 - val_acc: 0.1809\n",
      "Epoch 7/150\n",
      "  2/214 [..............................] - ETA: 6:23 - loss: 1.8583 - acc: 0.5625"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=150,\n",
    "    verbose=1,\n",
    "    callbacks=[reduceLROnPlat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('../models/custom_cnn_2d.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
