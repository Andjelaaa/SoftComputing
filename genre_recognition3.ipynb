{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Korisnik\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:72: UserWarning: h5py is running against HDF5 1.10.2 when it was built against 1.10.3, this may cause problems\n",
      "  '{0}.{1}.{2}'.format(*version.hdf5_built_version_tuple)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import h5py\n",
    "import librosa\n",
    "import itertools\n",
    "from copy import copy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Add\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.layers import Activation\n",
    "from tensorflow.keras.layers import PReLU\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import AveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling2D\n",
    "from tensorflow.keras.layers import Dropout\n",
    "from tensorflow.keras.layers import Flatten\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For reproducibility purposes\n",
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to split a song into multiple songs using overlapping windows\n",
    "\"\"\"\n",
    "def splitsongs(X, y, window = 0.05, overlap = 0.5):\n",
    "    # Empty lists to hold our results\n",
    "    temp_X = []\n",
    "    temp_y = []\n",
    "\n",
    "    # Get the input song array size\n",
    "    xshape = X.shape[0]\n",
    "    chunk = int(xshape*window)\n",
    "    offset = int(chunk*(1.-overlap))\n",
    "    \n",
    "    # Split the song and create new ones on windows\n",
    "    spsong = [X[i:i+chunk] for i in range(0, xshape - chunk + offset, offset)]\n",
    "    for s in spsong:\n",
    "        if s.shape[0] != chunk:\n",
    "            continue\n",
    "\n",
    "        temp_X.append(s)\n",
    "        temp_y.append(y)\n",
    "\n",
    "    return np.array(temp_X), np.array(temp_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "@description: Method to convert a list of songs to a np array of melspectrograms\n",
    "\"\"\"\n",
    "def to_melspectrogram(songs, n_fft=1024, hop_length=256):\n",
    "    # Transformation function\n",
    "    melspec = lambda x: librosa.feature.melspectrogram(x, n_fft=n_fft,\n",
    "        hop_length=hop_length, n_mels=128)[:,:,np.newaxis]\n",
    "\n",
    "    # map transformation of input songs to melspectrogram using log-scale\n",
    "    tsongs = map(melspec, songs)\n",
    "    # np.array([librosa.power_to_db(s, ref=np.max) for s in list(tsongs)])\n",
    "    return np.array(list(tsongs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def split_convert(X, y):\n",
    "    arr_specs, arr_genres = [], []\n",
    "    \n",
    "    # Convert to spectrograms and split into small windows\n",
    "    for fn, genre in zip(X, y):\n",
    "        signal, sr = librosa.load(fn)\n",
    "        signal = signal[:song_samples]\n",
    "\n",
    "        # Convert to dataset of spectograms/melspectograms\n",
    "        signals, y = splitsongs(signal, genre)\n",
    "\n",
    "        # Convert to \"spec\" representation\n",
    "        specs = to_melspectrogram(signals)\n",
    "\n",
    "        # Save files\n",
    "        arr_genres.extend(y)\n",
    "        arr_specs.extend(specs)\n",
    "    \n",
    "    return np.array(arr_specs), to_categorical(arr_genres)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def read_data(src_dir, genres, song_samples):    \n",
    "    # Empty array of dicts with the processed features from all files\n",
    "    arr_fn = []\n",
    "    arr_genres = []\n",
    "\n",
    "    # Get file list from the folders\n",
    "    for x,_ in genres.items():\n",
    "        folder = src_dir + x\n",
    "        for root, subdirs, files in os.walk(folder):\n",
    "            for file in files:\n",
    "                file_name = folder + \"/\" + file\n",
    "\n",
    "                # Save the file name and the genre\n",
    "                arr_fn.append(file_name)\n",
    "                arr_genres.append(genres[x])\n",
    "    \n",
    "    # Split into train and test\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        arr_fn, arr_genres, test_size=0.3, random_state=42, stratify=arr_genres\n",
    "    )\n",
    "    \n",
    "    # Split into small segments and convert to spectrogram\n",
    "    X_train, y_train = split_convert(X_train, y_train)\n",
    "    X_test, y_test = split_convert(X_test, y_test)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "gtzan_dir = 'Data/genres_original/'\n",
    "song_samples = 660000\n",
    "genres = {'metal': 0, 'disco': 1, 'classical': 2, 'hiphop': 3, 'jazz': 4, \n",
    "          'country': 5, 'pop': 6, 'blues': 7, 'reggae': 8, 'rock': 9}\n",
    "\n",
    "# Read the data\n",
    "X_train, X_test, y_train, y_test = read_data(gtzan_dir, genres, song_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27300, 128, 129, 1) (11700, 128, 129, 1) (27300, 10) (11700, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class GTZANGenerator(Sequence):\n",
    "    def __init__(self, X, y, batch_size=64, is_test = False):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.batch_size = batch_size\n",
    "        self.is_test = is_test\n",
    "    \n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.X)/self.batch_size))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        # Get batch indexes\n",
    "        signals = self.X[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Apply data augmentation\n",
    "        if not self.is_test:\n",
    "            signals = self.__augment(signals)\n",
    "        return signals, self.y[index*self.batch_size:(index+1)*self.batch_size]\n",
    "    \n",
    "    def __augment(self, signals, hor_flip = 0.5, random_cutout = 0.5):\n",
    "        spectrograms =  []\n",
    "        for s in signals:\n",
    "            signal = copy(s)\n",
    "            \n",
    "            # Perform horizontal flip\n",
    "            if np.random.rand() < hor_flip:\n",
    "                signal = np.flip(signal, 1)\n",
    "\n",
    "            # Perform random cutoout of some frequency/time\n",
    "            if np.random.rand() < random_cutout:\n",
    "                lines = np.random.randint(signal.shape[0], size=3)\n",
    "                cols = np.random.randint(signal.shape[0], size=4)\n",
    "                signal[lines, :, :] = -80 # dB\n",
    "                signal[:, cols, :] = -80 # dB\n",
    "\n",
    "            spectrograms.append(signal)\n",
    "        return np.array(spectrograms)\n",
    "    \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        np.random.shuffle(self.indexes)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_block(x, n_filters, pool_size=(2, 2)):\n",
    "    x = Conv2D(n_filters, (3, 3), strides=(1, 1), padding='same')(x)\n",
    "    x = Activation('relu')(x)\n",
    "    x = MaxPooling2D(pool_size=pool_size, strides=pool_size)(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model Definition\n",
    "def create_model(input_shape, num_genres):\n",
    "    inpt = Input(shape=input_shape)\n",
    "    x = conv_block(inpt, 16)\n",
    "    x = conv_block(x, 32)\n",
    "    x = conv_block(x, 64)\n",
    "    x = conv_block(x, 128)\n",
    "    x = conv_block(x, 256)\n",
    "    \n",
    "    # Global Pooling and MLP\n",
    "    x = Flatten()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(512, activation='relu', \n",
    "              kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    x = Dropout(0.25)(x)\n",
    "    predictions = Dense(num_genres, \n",
    "                        activation='softmax', \n",
    "                        kernel_regularizer=tf.keras.regularizers.l2(0.02))(x)\n",
    "    \n",
    "    model = Model(inputs=inpt, outputs=predictions)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_model(X_train[0].shape, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 128, 129, 1)]     0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 128, 129, 16)      160       \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 128, 129, 16)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 64, 64, 32)        4640      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 64, 64, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32, 32, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 32, 32, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 16, 16, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 128)       73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 16, 16, 128)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 8, 8, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 8, 8, 256)         295168    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 8, 8, 256)         0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4, 4, 256)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 512)               2097664   \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 2,495,114\n",
      "Trainable params: 2,495,114\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss=tf.keras.losses.categorical_crossentropy,\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduceLROnPlat = ReduceLROnPlateau(\n",
    "    monitor='val_loss', \n",
    "    factor=0.95,\n",
    "    patience=3,\n",
    "    verbose=1,\n",
    "    mode='min',\n",
    "    min_delta=0.0001,\n",
    "    cooldown=2,\n",
    "    min_lr=1e-5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generators\n",
    "batch_size = 128\n",
    "train_generator = GTZANGenerator(X_train, y_train)\n",
    "steps_per_epoch = np.ceil(len(X_train)/batch_size)\n",
    "\n",
    "validation_generator = GTZANGenerator(X_test, y_test)\n",
    "val_steps = np.ceil(len(X_test)/batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-19-c619abd23725>:8: Model.fit_generator (from tensorflow.python.keras.engine.training) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use Model.fit, which supports generators.\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "WARNING:tensorflow:sample_weight modes were coerced from\n",
      "  ...\n",
      "    to  \n",
      "  ['...']\n",
      "Train for 214.0 steps, validate for 92.0 steps\n",
      "Epoch 1/150\n",
      "214/214 [==============================] - 182s 852ms/step - loss: 11.2627 - accuracy: 0.1341 - val_loss: 5.2659 - val_accuracy: 0.2176\n",
      "Epoch 2/150\n",
      "214/214 [==============================] - 187s 876ms/step - loss: 3.8047 - accuracy: 0.2030 - val_loss: 2.9560 - val_accuracy: 0.1768\n",
      "Epoch 3/150\n",
      "214/214 [==============================] - 182s 852ms/step - loss: 2.6461 - accuracy: 0.2118 - val_loss: 2.4208 - val_accuracy: 0.2393\n",
      "Epoch 4/150\n",
      "214/214 [==============================] - 186s 871ms/step - loss: 2.3684 - accuracy: 0.1940 - val_loss: 2.3453 - val_accuracy: 0.1551\n",
      "Epoch 5/150\n",
      "214/214 [==============================] - 192s 897ms/step - loss: 2.2736 - accuracy: 0.1901 - val_loss: 2.1637 - val_accuracy: 0.2164\n",
      "Epoch 6/150\n",
      "214/214 [==============================] - 188s 880ms/step - loss: 2.1699 - accuracy: 0.1944 - val_loss: 2.0709 - val_accuracy: 0.2420\n",
      "Epoch 7/150\n",
      "214/214 [==============================] - 183s 855ms/step - loss: 2.1388 - accuracy: 0.2133 - val_loss: 2.1085 - val_accuracy: 0.1792\n",
      "Epoch 8/150\n",
      "214/214 [==============================] - 180s 843ms/step - loss: 2.1017 - accuracy: 0.2355 - val_loss: 2.1101 - val_accuracy: 0.2283\n",
      "Epoch 9/150\n",
      "214/214 [==============================] - 183s 857ms/step - loss: 2.0874 - accuracy: 0.2287 - val_loss: 2.0087 - val_accuracy: 0.2408\n",
      "Epoch 10/150\n",
      "214/214 [==============================] - 185s 866ms/step - loss: 2.0345 - accuracy: 0.2396 - val_loss: 1.9589 - val_accuracy: 0.2293\n",
      "Epoch 11/150\n",
      "214/214 [==============================] - 175s 819ms/step - loss: 2.0138 - accuracy: 0.2727 - val_loss: 2.0316 - val_accuracy: 0.2327\n",
      "Epoch 12/150\n",
      "214/214 [==============================] - 177s 825ms/step - loss: 2.0062 - accuracy: 0.2654 - val_loss: 1.9062 - val_accuracy: 0.2836\n",
      "Epoch 13/150\n",
      "214/214 [==============================] - 176s 824ms/step - loss: 1.9882 - accuracy: 0.2743 - val_loss: 1.9063 - val_accuracy: 0.2527\n",
      "Epoch 14/150\n",
      "214/214 [==============================] - 177s 827ms/step - loss: 1.9859 - accuracy: 0.2735 - val_loss: 1.8804 - val_accuracy: 0.2814\n",
      "Epoch 15/150\n",
      "214/214 [==============================] - 178s 831ms/step - loss: 1.9951 - accuracy: 0.2655 - val_loss: 1.9525 - val_accuracy: 0.2926\n",
      "Epoch 16/150\n",
      "214/214 [==============================] - 178s 832ms/step - loss: 1.9277 - accuracy: 0.2894 - val_loss: 1.9742 - val_accuracy: 0.2768\n",
      "Epoch 17/150\n",
      "214/214 [==============================] - 178s 832ms/step - loss: 1.9743 - accuracy: 0.2825 - val_loss: 1.8317 - val_accuracy: 0.3227\n",
      "Epoch 18/150\n",
      "214/214 [==============================] - 178s 831ms/step - loss: 1.9792 - accuracy: 0.2639 - val_loss: 1.9886 - val_accuracy: 0.2571\n",
      "Epoch 19/150\n",
      "214/214 [==============================] - 182s 848ms/step - loss: 1.9407 - accuracy: 0.2928 - val_loss: 1.8389 - val_accuracy: 0.3312\n",
      "Epoch 20/150\n",
      "214/214 [==============================] - 181s 846ms/step - loss: 1.9373 - accuracy: 0.2917 - val_loss: 1.8156 - val_accuracy: 0.3145\n",
      "Epoch 21/150\n",
      "214/214 [==============================] - 176s 822ms/step - loss: 1.9259 - accuracy: 0.3124 - val_loss: 1.8331 - val_accuracy: 0.2867\n",
      "Epoch 22/150\n",
      "214/214 [==============================] - 176s 822ms/step - loss: 1.9111 - accuracy: 0.3107 - val_loss: 1.7500 - val_accuracy: 0.4000\n",
      "Epoch 23/150\n",
      "214/214 [==============================] - 177s 826ms/step - loss: 1.9005 - accuracy: 0.3209 - val_loss: 1.7471 - val_accuracy: 0.3526\n",
      "Epoch 24/150\n",
      "214/214 [==============================] - 183s 856ms/step - loss: 1.8813 - accuracy: 0.3302 - val_loss: 1.7144 - val_accuracy: 0.4482\n",
      "Epoch 25/150\n",
      "214/214 [==============================] - 192s 896ms/step - loss: 1.9150 - accuracy: 0.3202 - val_loss: 1.7912 - val_accuracy: 0.4088\n",
      "Epoch 26/150\n",
      "214/214 [==============================] - 211s 987ms/step - loss: 1.8461 - accuracy: 0.3531 - val_loss: 1.6827 - val_accuracy: 0.4377\n",
      "Epoch 27/150\n",
      "214/214 [==============================] - 210s 980ms/step - loss: 1.8516 - accuracy: 0.3704 - val_loss: 1.7048 - val_accuracy: 0.4266\n",
      "Epoch 28/150\n",
      "214/214 [==============================] - 809s 4s/step - loss: 1.7517 - accuracy: 0.4022 - val_loss: 1.6626 - val_accuracy: 0.4153\n",
      "Epoch 29/150\n",
      "214/214 [==============================] - 181s 845ms/step - loss: 1.7805 - accuracy: 0.4007 - val_loss: 1.6652 - val_accuracy: 0.4524\n",
      "Epoch 30/150\n",
      "214/214 [==============================] - 175s 816ms/step - loss: 1.7363 - accuracy: 0.3904 - val_loss: 1.6350 - val_accuracy: 0.4288\n",
      "Epoch 31/150\n",
      "214/214 [==============================] - 173s 808ms/step - loss: 1.7031 - accuracy: 0.3992 - val_loss: 1.5607 - val_accuracy: 0.4608\n",
      "Epoch 32/150\n",
      "214/214 [==============================] - 179s 839ms/step - loss: 1.6430 - accuracy: 0.4396 - val_loss: 1.6031 - val_accuracy: 0.4417\n",
      "Epoch 33/150\n",
      "214/214 [==============================] - 201s 940ms/step - loss: 1.7027 - accuracy: 0.4127 - val_loss: 1.6467 - val_accuracy: 0.4457\n",
      "Epoch 34/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.6724 - accuracy: 0.4274\n",
      "Epoch 00034: ReduceLROnPlateau reducing learning rate to 0.0009500000451225787.\n",
      "214/214 [==============================] - 193s 903ms/step - loss: 1.6745 - accuracy: 0.4262 - val_loss: 1.6041 - val_accuracy: 0.4295\n",
      "Epoch 35/150\n",
      "214/214 [==============================] - 179s 836ms/step - loss: 1.6645 - accuracy: 0.4336 - val_loss: 1.5839 - val_accuracy: 0.4409\n",
      "Epoch 36/150\n",
      "214/214 [==============================] - 200s 935ms/step - loss: 1.6487 - accuracy: 0.4435 - val_loss: 1.5435 - val_accuracy: 0.4913\n",
      "Epoch 37/150\n",
      "214/214 [==============================] - 223s 1s/step - loss: 1.7156 - accuracy: 0.4295 - val_loss: 1.5456 - val_accuracy: 0.4878\n",
      "Epoch 38/150\n",
      "214/214 [==============================] - 180s 839ms/step - loss: 1.6343 - accuracy: 0.4438 - val_loss: 1.4779 - val_accuracy: 0.5326\n",
      "Epoch 39/150\n",
      "214/214 [==============================] - 184s 858ms/step - loss: 1.5756 - accuracy: 0.4731 - val_loss: 1.4915 - val_accuracy: 0.5170\n",
      "Epoch 40/150\n",
      "214/214 [==============================] - 178s 833ms/step - loss: 1.6429 - accuracy: 0.4384 - val_loss: 1.5531 - val_accuracy: 0.4754\n",
      "Epoch 41/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.5921 - accuracy: 0.4484\n",
      "Epoch 00041: ReduceLROnPlateau reducing learning rate to 0.0009025000152178108.\n",
      "214/214 [==============================] - 177s 827ms/step - loss: 1.5943 - accuracy: 0.4474 - val_loss: 1.5541 - val_accuracy: 0.5070\n",
      "Epoch 42/150\n",
      "214/214 [==============================] - 174s 813ms/step - loss: 1.5776 - accuracy: 0.4859 - val_loss: 1.4661 - val_accuracy: 0.5059\n",
      "Epoch 43/150\n",
      "214/214 [==============================] - 173s 809ms/step - loss: 1.5975 - accuracy: 0.4682 - val_loss: 1.5215 - val_accuracy: 0.5022\n",
      "Epoch 44/150\n",
      "214/214 [==============================] - 178s 831ms/step - loss: 1.5676 - accuracy: 0.4819 - val_loss: 1.4112 - val_accuracy: 0.5138\n",
      "Epoch 45/150\n",
      "214/214 [==============================] - 178s 833ms/step - loss: 1.6140 - accuracy: 0.4704 - val_loss: 1.4708 - val_accuracy: 0.4935\n",
      "Epoch 46/150\n",
      "214/214 [==============================] - 181s 847ms/step - loss: 1.5149 - accuracy: 0.5020 - val_loss: 1.5554 - val_accuracy: 0.4985\n",
      "Epoch 47/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.4874 - accuracy: 0.5142\n",
      "Epoch 00047: ReduceLROnPlateau reducing learning rate to 0.0008573750033974647.\n",
      "214/214 [==============================] - 177s 825ms/step - loss: 1.4893 - accuracy: 0.5126 - val_loss: 1.4399 - val_accuracy: 0.5299\n",
      "Epoch 48/150\n",
      "214/214 [==============================] - 172s 802ms/step - loss: 1.5537 - accuracy: 0.4842 - val_loss: 1.3908 - val_accuracy: 0.5656\n",
      "Epoch 49/150\n",
      "214/214 [==============================] - 178s 830ms/step - loss: 1.4787 - accuracy: 0.5207 - val_loss: 1.4672 - val_accuracy: 0.5443\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/150\n",
      "214/214 [==============================] - 183s 855ms/step - loss: 1.5416 - accuracy: 0.4946 - val_loss: 1.4111 - val_accuracy: 0.5825\n",
      "Epoch 51/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.5041 - accuracy: 0.5153\n",
      "Epoch 00051: ReduceLROnPlateau reducing learning rate to 0.0008145062311086804.\n",
      "214/214 [==============================] - 171s 801ms/step - loss: 1.5027 - accuracy: 0.5162 - val_loss: 1.5005 - val_accuracy: 0.5231\n",
      "Epoch 52/150\n",
      "214/214 [==============================] - 177s 827ms/step - loss: 1.4893 - accuracy: 0.5222 - val_loss: 1.3710 - val_accuracy: 0.5725\n",
      "Epoch 53/150\n",
      "214/214 [==============================] - 178s 831ms/step - loss: 1.4512 - accuracy: 0.5250 - val_loss: 1.4062 - val_accuracy: 0.5633\n",
      "Epoch 54/150\n",
      "214/214 [==============================] - 172s 805ms/step - loss: 1.4444 - accuracy: 0.5402 - val_loss: 1.4251 - val_accuracy: 0.5443\n",
      "Epoch 55/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.4711 - accuracy: 0.5387\n",
      "Epoch 00055: ReduceLROnPlateau reducing learning rate to 0.0007737808919046074.\n",
      "214/214 [==============================] - 173s 809ms/step - loss: 1.4743 - accuracy: 0.5366 - val_loss: 1.5045 - val_accuracy: 0.5168\n",
      "Epoch 56/150\n",
      "214/214 [==============================] - 173s 806ms/step - loss: 1.5149 - accuracy: 0.5188 - val_loss: 1.4874 - val_accuracy: 0.5211\n",
      "Epoch 57/150\n",
      "214/214 [==============================] - 181s 844ms/step - loss: 1.3934 - accuracy: 0.5590 - val_loss: 1.3212 - val_accuracy: 0.5759\n",
      "Epoch 58/150\n",
      "214/214 [==============================] - 174s 812ms/step - loss: 1.4140 - accuracy: 0.5522 - val_loss: 1.3112 - val_accuracy: 0.5948\n",
      "Epoch 59/150\n",
      "214/214 [==============================] - 178s 830ms/step - loss: 1.4459 - accuracy: 0.5558 - val_loss: 1.3370 - val_accuracy: 0.5496\n",
      "Epoch 60/150\n",
      "214/214 [==============================] - 177s 825ms/step - loss: 1.3950 - accuracy: 0.5546 - val_loss: 1.3000 - val_accuracy: 0.5990\n",
      "Epoch 61/150\n",
      "214/214 [==============================] - 179s 838ms/step - loss: 1.4657 - accuracy: 0.5385 - val_loss: 1.3695 - val_accuracy: 0.5810\n",
      "Epoch 62/150\n",
      "214/214 [==============================] - 178s 830ms/step - loss: 1.3825 - accuracy: 0.5737 - val_loss: 1.3055 - val_accuracy: 0.5995\n",
      "Epoch 63/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.3637 - accuracy: 0.5693\n",
      "Epoch 00063: ReduceLROnPlateau reducing learning rate to 0.000735091819660738.\n",
      "214/214 [==============================] - 178s 831ms/step - loss: 1.3676 - accuracy: 0.5677 - val_loss: 1.4378 - val_accuracy: 0.5679\n",
      "Epoch 64/150\n",
      "214/214 [==============================] - 180s 840ms/step - loss: 1.3750 - accuracy: 0.5735 - val_loss: 1.2778 - val_accuracy: 0.6121\n",
      "Epoch 65/150\n",
      "214/214 [==============================] - 178s 834ms/step - loss: 1.3577 - accuracy: 0.5838 - val_loss: 1.3432 - val_accuracy: 0.5756\n",
      "Epoch 66/150\n",
      "214/214 [==============================] - 176s 821ms/step - loss: 1.3546 - accuracy: 0.5802 - val_loss: 1.3845 - val_accuracy: 0.5873\n",
      "Epoch 67/150\n",
      "213/214 [============================>.] - ETA: 0s - loss: 1.3959 - accuracy: 0.5697\n",
      "Epoch 00067: ReduceLROnPlateau reducing learning rate to 0.0006983372120885178.\n",
      "214/214 [==============================] - 186s 869ms/step - loss: 1.3980 - accuracy: 0.5688 - val_loss: 1.2941 - val_accuracy: 0.6160\n",
      "Epoch 68/150\n",
      "214/214 [==============================] - 184s 859ms/step - loss: 1.3184 - accuracy: 0.5919 - val_loss: 1.2560 - val_accuracy: 0.5983\n",
      "Epoch 69/150\n",
      "214/214 [==============================] - 175s 819ms/step - loss: 1.3172 - accuracy: 0.5979 - val_loss: 1.2349 - val_accuracy: 0.6126\n",
      "Epoch 70/150\n",
      "214/214 [==============================] - 173s 808ms/step - loss: 1.3353 - accuracy: 0.5945 - val_loss: 1.2595 - val_accuracy: 0.6231\n",
      "Epoch 71/150\n",
      "207/214 [============================>.] - ETA: 5s - loss: 1.2949 - accuracy: 0.6069"
     ]
    }
   ],
   "source": [
    "hist = model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=steps_per_epoch,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=val_steps,\n",
    "    epochs=150,\n",
    "    verbose=1,\n",
    "    callbacks=[reduceLROnPlat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('../models/custom_cnn_2d.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
