{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "genre_recognition2.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wjyyroPnh7W2"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import scipy\r\n",
        "import sys\r\n",
        "import os\r\n",
        "import pickle\r\n",
        "import librosa\r\n",
        "import librosa.display\r\n",
        "from IPython.display import Audio\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "import tensorflow as tf\r\n",
        "from tensorflow import keras\r\n",
        "%matplotlib inline\r\n",
        "from keras import layers\r\n",
        "import keras"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nrgXAkmadpqJ",
        "outputId": "22838492-c737-4378-ecf9-a8587c6b4ab2"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wWxOMfcJy2Zb"
      },
      "source": [
        "!unzip -q /content/drive/MyDrive/archive.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "id": "zLoUhIRlzUT0",
        "outputId": "32998f75-5ddc-4c22-9a9b-933d6d0b1c74"
      },
      "source": [
        "df1 = pd.read_csv('/content/Data/features_3_sec.csv')\r\n",
        "df1.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>filename</th>\n",
              "      <th>length</th>\n",
              "      <th>chroma_stft_mean</th>\n",
              "      <th>chroma_stft_var</th>\n",
              "      <th>rms_mean</th>\n",
              "      <th>rms_var</th>\n",
              "      <th>spectral_centroid_mean</th>\n",
              "      <th>spectral_centroid_var</th>\n",
              "      <th>spectral_bandwidth_mean</th>\n",
              "      <th>spectral_bandwidth_var</th>\n",
              "      <th>rolloff_mean</th>\n",
              "      <th>rolloff_var</th>\n",
              "      <th>zero_crossing_rate_mean</th>\n",
              "      <th>zero_crossing_rate_var</th>\n",
              "      <th>harmony_mean</th>\n",
              "      <th>harmony_var</th>\n",
              "      <th>perceptr_mean</th>\n",
              "      <th>perceptr_var</th>\n",
              "      <th>tempo</th>\n",
              "      <th>mfcc1_mean</th>\n",
              "      <th>mfcc1_var</th>\n",
              "      <th>mfcc2_mean</th>\n",
              "      <th>mfcc2_var</th>\n",
              "      <th>mfcc3_mean</th>\n",
              "      <th>mfcc3_var</th>\n",
              "      <th>mfcc4_mean</th>\n",
              "      <th>mfcc4_var</th>\n",
              "      <th>mfcc5_mean</th>\n",
              "      <th>mfcc5_var</th>\n",
              "      <th>mfcc6_mean</th>\n",
              "      <th>mfcc6_var</th>\n",
              "      <th>mfcc7_mean</th>\n",
              "      <th>mfcc7_var</th>\n",
              "      <th>mfcc8_mean</th>\n",
              "      <th>mfcc8_var</th>\n",
              "      <th>mfcc9_mean</th>\n",
              "      <th>mfcc9_var</th>\n",
              "      <th>mfcc10_mean</th>\n",
              "      <th>mfcc10_var</th>\n",
              "      <th>mfcc11_mean</th>\n",
              "      <th>mfcc11_var</th>\n",
              "      <th>mfcc12_mean</th>\n",
              "      <th>mfcc12_var</th>\n",
              "      <th>mfcc13_mean</th>\n",
              "      <th>mfcc13_var</th>\n",
              "      <th>mfcc14_mean</th>\n",
              "      <th>mfcc14_var</th>\n",
              "      <th>mfcc15_mean</th>\n",
              "      <th>mfcc15_var</th>\n",
              "      <th>mfcc16_mean</th>\n",
              "      <th>mfcc16_var</th>\n",
              "      <th>mfcc17_mean</th>\n",
              "      <th>mfcc17_var</th>\n",
              "      <th>mfcc18_mean</th>\n",
              "      <th>mfcc18_var</th>\n",
              "      <th>mfcc19_mean</th>\n",
              "      <th>mfcc19_var</th>\n",
              "      <th>mfcc20_mean</th>\n",
              "      <th>mfcc20_var</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>blues.00000.0.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.335406</td>\n",
              "      <td>0.091048</td>\n",
              "      <td>0.130405</td>\n",
              "      <td>0.003521</td>\n",
              "      <td>1773.065032</td>\n",
              "      <td>167541.630869</td>\n",
              "      <td>1972.744388</td>\n",
              "      <td>117335.771563</td>\n",
              "      <td>3714.560359</td>\n",
              "      <td>1.080790e+06</td>\n",
              "      <td>0.081851</td>\n",
              "      <td>0.000558</td>\n",
              "      <td>-0.000078</td>\n",
              "      <td>0.008354</td>\n",
              "      <td>-0.000068</td>\n",
              "      <td>0.005535</td>\n",
              "      <td>129.199219</td>\n",
              "      <td>-118.627914</td>\n",
              "      <td>2440.286621</td>\n",
              "      <td>125.083626</td>\n",
              "      <td>260.956909</td>\n",
              "      <td>-23.443724</td>\n",
              "      <td>364.081726</td>\n",
              "      <td>41.321484</td>\n",
              "      <td>181.694855</td>\n",
              "      <td>-5.976108</td>\n",
              "      <td>152.963135</td>\n",
              "      <td>20.115141</td>\n",
              "      <td>75.652298</td>\n",
              "      <td>-16.045410</td>\n",
              "      <td>40.227104</td>\n",
              "      <td>17.855198</td>\n",
              "      <td>84.320282</td>\n",
              "      <td>-14.633434</td>\n",
              "      <td>83.437233</td>\n",
              "      <td>10.270527</td>\n",
              "      <td>97.001335</td>\n",
              "      <td>-9.708279</td>\n",
              "      <td>66.669891</td>\n",
              "      <td>10.183875</td>\n",
              "      <td>45.103611</td>\n",
              "      <td>-4.681614</td>\n",
              "      <td>34.169498</td>\n",
              "      <td>8.417439</td>\n",
              "      <td>48.269444</td>\n",
              "      <td>-7.233477</td>\n",
              "      <td>42.770947</td>\n",
              "      <td>-2.853603</td>\n",
              "      <td>39.687145</td>\n",
              "      <td>-3.241280</td>\n",
              "      <td>36.488243</td>\n",
              "      <td>0.722209</td>\n",
              "      <td>38.099152</td>\n",
              "      <td>-5.050335</td>\n",
              "      <td>33.618073</td>\n",
              "      <td>-0.243027</td>\n",
              "      <td>43.771767</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>blues.00000.1.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.343065</td>\n",
              "      <td>0.086147</td>\n",
              "      <td>0.112699</td>\n",
              "      <td>0.001450</td>\n",
              "      <td>1816.693777</td>\n",
              "      <td>90525.690866</td>\n",
              "      <td>2010.051501</td>\n",
              "      <td>65671.875673</td>\n",
              "      <td>3869.682242</td>\n",
              "      <td>6.722448e+05</td>\n",
              "      <td>0.087173</td>\n",
              "      <td>0.001030</td>\n",
              "      <td>-0.000099</td>\n",
              "      <td>0.004950</td>\n",
              "      <td>-0.000103</td>\n",
              "      <td>0.004854</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-125.590706</td>\n",
              "      <td>2038.344238</td>\n",
              "      <td>122.421227</td>\n",
              "      <td>216.774185</td>\n",
              "      <td>-20.718019</td>\n",
              "      <td>231.979767</td>\n",
              "      <td>50.128387</td>\n",
              "      <td>142.700409</td>\n",
              "      <td>-11.333302</td>\n",
              "      <td>139.243118</td>\n",
              "      <td>21.385401</td>\n",
              "      <td>77.817947</td>\n",
              "      <td>-15.960796</td>\n",
              "      <td>97.364029</td>\n",
              "      <td>19.454103</td>\n",
              "      <td>57.948093</td>\n",
              "      <td>-12.465918</td>\n",
              "      <td>68.271523</td>\n",
              "      <td>17.898169</td>\n",
              "      <td>56.222176</td>\n",
              "      <td>-11.732554</td>\n",
              "      <td>54.373909</td>\n",
              "      <td>8.145000</td>\n",
              "      <td>40.662876</td>\n",
              "      <td>-7.717751</td>\n",
              "      <td>30.808521</td>\n",
              "      <td>8.397150</td>\n",
              "      <td>48.784225</td>\n",
              "      <td>-8.300493</td>\n",
              "      <td>68.584824</td>\n",
              "      <td>4.074709</td>\n",
              "      <td>64.748276</td>\n",
              "      <td>-6.055294</td>\n",
              "      <td>40.677654</td>\n",
              "      <td>0.159015</td>\n",
              "      <td>51.264091</td>\n",
              "      <td>-2.837699</td>\n",
              "      <td>97.030830</td>\n",
              "      <td>5.784063</td>\n",
              "      <td>59.943081</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>blues.00000.2.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.346815</td>\n",
              "      <td>0.092243</td>\n",
              "      <td>0.132003</td>\n",
              "      <td>0.004620</td>\n",
              "      <td>1788.539719</td>\n",
              "      <td>111407.437613</td>\n",
              "      <td>2084.565132</td>\n",
              "      <td>75124.921716</td>\n",
              "      <td>3997.639160</td>\n",
              "      <td>7.907127e+05</td>\n",
              "      <td>0.071383</td>\n",
              "      <td>0.000425</td>\n",
              "      <td>-0.000066</td>\n",
              "      <td>0.012476</td>\n",
              "      <td>0.000065</td>\n",
              "      <td>0.004357</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-132.441940</td>\n",
              "      <td>3798.532227</td>\n",
              "      <td>115.085175</td>\n",
              "      <td>257.321289</td>\n",
              "      <td>-14.811666</td>\n",
              "      <td>192.448074</td>\n",
              "      <td>50.189293</td>\n",
              "      <td>144.166031</td>\n",
              "      <td>-0.680819</td>\n",
              "      <td>128.376892</td>\n",
              "      <td>24.650375</td>\n",
              "      <td>66.371170</td>\n",
              "      <td>-13.506104</td>\n",
              "      <td>89.319336</td>\n",
              "      <td>15.643386</td>\n",
              "      <td>55.253967</td>\n",
              "      <td>-13.216637</td>\n",
              "      <td>120.308784</td>\n",
              "      <td>10.406025</td>\n",
              "      <td>35.757862</td>\n",
              "      <td>-7.991465</td>\n",
              "      <td>47.911613</td>\n",
              "      <td>11.853963</td>\n",
              "      <td>36.569931</td>\n",
              "      <td>-4.677677</td>\n",
              "      <td>40.725075</td>\n",
              "      <td>6.571110</td>\n",
              "      <td>30.686846</td>\n",
              "      <td>-2.424750</td>\n",
              "      <td>50.313499</td>\n",
              "      <td>4.806280</td>\n",
              "      <td>67.336563</td>\n",
              "      <td>-1.768610</td>\n",
              "      <td>28.348579</td>\n",
              "      <td>2.378768</td>\n",
              "      <td>45.717648</td>\n",
              "      <td>-1.938424</td>\n",
              "      <td>53.050835</td>\n",
              "      <td>2.517375</td>\n",
              "      <td>33.105122</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>blues.00000.3.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.363639</td>\n",
              "      <td>0.086856</td>\n",
              "      <td>0.132565</td>\n",
              "      <td>0.002448</td>\n",
              "      <td>1655.289045</td>\n",
              "      <td>111952.284517</td>\n",
              "      <td>1960.039988</td>\n",
              "      <td>82913.639269</td>\n",
              "      <td>3568.300218</td>\n",
              "      <td>9.216524e+05</td>\n",
              "      <td>0.069426</td>\n",
              "      <td>0.000304</td>\n",
              "      <td>-0.000014</td>\n",
              "      <td>0.008318</td>\n",
              "      <td>0.000018</td>\n",
              "      <td>0.005927</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-118.231087</td>\n",
              "      <td>2508.781006</td>\n",
              "      <td>132.116501</td>\n",
              "      <td>332.650574</td>\n",
              "      <td>-18.758335</td>\n",
              "      <td>109.357529</td>\n",
              "      <td>39.769306</td>\n",
              "      <td>184.693344</td>\n",
              "      <td>-13.260426</td>\n",
              "      <td>144.398224</td>\n",
              "      <td>20.468134</td>\n",
              "      <td>122.516464</td>\n",
              "      <td>-14.563448</td>\n",
              "      <td>68.937332</td>\n",
              "      <td>18.745104</td>\n",
              "      <td>74.748886</td>\n",
              "      <td>-13.755463</td>\n",
              "      <td>73.868576</td>\n",
              "      <td>12.993759</td>\n",
              "      <td>41.549564</td>\n",
              "      <td>-12.648887</td>\n",
              "      <td>58.540478</td>\n",
              "      <td>10.389314</td>\n",
              "      <td>39.102024</td>\n",
              "      <td>-4.362739</td>\n",
              "      <td>60.714748</td>\n",
              "      <td>9.156193</td>\n",
              "      <td>40.411537</td>\n",
              "      <td>-9.889441</td>\n",
              "      <td>44.666325</td>\n",
              "      <td>-1.359111</td>\n",
              "      <td>47.739452</td>\n",
              "      <td>-3.841155</td>\n",
              "      <td>28.337118</td>\n",
              "      <td>1.218588</td>\n",
              "      <td>34.770935</td>\n",
              "      <td>-3.580352</td>\n",
              "      <td>50.836224</td>\n",
              "      <td>3.630866</td>\n",
              "      <td>32.023678</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>blues.00000.4.wav</td>\n",
              "      <td>66149</td>\n",
              "      <td>0.335579</td>\n",
              "      <td>0.088129</td>\n",
              "      <td>0.143289</td>\n",
              "      <td>0.001701</td>\n",
              "      <td>1630.656199</td>\n",
              "      <td>79667.267654</td>\n",
              "      <td>1948.503884</td>\n",
              "      <td>60204.020268</td>\n",
              "      <td>3469.992864</td>\n",
              "      <td>6.102111e+05</td>\n",
              "      <td>0.070095</td>\n",
              "      <td>0.000289</td>\n",
              "      <td>0.000041</td>\n",
              "      <td>0.009634</td>\n",
              "      <td>-0.000106</td>\n",
              "      <td>0.005833</td>\n",
              "      <td>123.046875</td>\n",
              "      <td>-105.968376</td>\n",
              "      <td>2118.919922</td>\n",
              "      <td>134.643646</td>\n",
              "      <td>219.562622</td>\n",
              "      <td>-19.961748</td>\n",
              "      <td>171.878754</td>\n",
              "      <td>40.171753</td>\n",
              "      <td>103.120712</td>\n",
              "      <td>-14.271939</td>\n",
              "      <td>102.651230</td>\n",
              "      <td>18.734617</td>\n",
              "      <td>79.070000</td>\n",
              "      <td>-15.619381</td>\n",
              "      <td>48.510284</td>\n",
              "      <td>19.207966</td>\n",
              "      <td>53.642956</td>\n",
              "      <td>-18.274683</td>\n",
              "      <td>95.300995</td>\n",
              "      <td>14.316693</td>\n",
              "      <td>58.821163</td>\n",
              "      <td>-5.792194</td>\n",
              "      <td>55.030254</td>\n",
              "      <td>17.045437</td>\n",
              "      <td>43.229939</td>\n",
              "      <td>-5.681399</td>\n",
              "      <td>46.515259</td>\n",
              "      <td>5.705521</td>\n",
              "      <td>24.956211</td>\n",
              "      <td>-7.986080</td>\n",
              "      <td>39.816933</td>\n",
              "      <td>2.092937</td>\n",
              "      <td>30.336359</td>\n",
              "      <td>0.664582</td>\n",
              "      <td>45.880913</td>\n",
              "      <td>1.689446</td>\n",
              "      <td>51.363583</td>\n",
              "      <td>-3.392489</td>\n",
              "      <td>26.738789</td>\n",
              "      <td>0.536961</td>\n",
              "      <td>29.146694</td>\n",
              "      <td>blues</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "            filename  length  chroma_stft_mean  ...  mfcc20_mean  mfcc20_var  label\n",
              "0  blues.00000.0.wav   66149          0.335406  ...    -0.243027   43.771767  blues\n",
              "1  blues.00000.1.wav   66149          0.343065  ...     5.784063   59.943081  blues\n",
              "2  blues.00000.2.wav   66149          0.346815  ...     2.517375   33.105122  blues\n",
              "3  blues.00000.3.wav   66149          0.363639  ...     3.630866   32.023678  blues\n",
              "4  blues.00000.4.wav   66149          0.335579  ...     0.536961   29.146694  blues\n",
              "\n",
              "[5 rows x 60 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqlvSuzM0Hr4",
        "outputId": "a349fa7a-ef9b-4191-cc3b-4897d88a845b"
      },
      "source": [
        "# df1.dtypes\r\n",
        "df1 = df1.drop(labels='filename',axis=1)\r\n",
        "genre_list = df1.iloc[:, -1]\r\n",
        "encoder = LabelEncoder()\r\n",
        "y = encoder.fit_transform(genre_list)\r\n",
        "print(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 ... 9 9 9]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MmHcQCQc0fVN",
        "outputId": "288e8c46-84b0-4237-9b12-6fb834e1f18c"
      },
      "source": [
        "print(df1.iloc[:, :-1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      length  chroma_stft_mean  ...  mfcc20_mean  mfcc20_var\n",
            "0      66149          0.335406  ...    -0.243027   43.771767\n",
            "1      66149          0.343065  ...     5.784063   59.943081\n",
            "2      66149          0.346815  ...     2.517375   33.105122\n",
            "3      66149          0.363639  ...     3.630866   32.023678\n",
            "4      66149          0.335579  ...     0.536961   29.146694\n",
            "...      ...               ...  ...          ...         ...\n",
            "9985   66149          0.349126  ...     1.818823   38.966969\n",
            "9986   66149          0.372564  ...     0.428857   18.697033\n",
            "9987   66149          0.347481  ...    -0.299545   41.586990\n",
            "9988   66149          0.387527  ...     0.675824   12.787750\n",
            "9989   66149          0.369293  ...    -3.412534   31.727489\n",
            "\n",
            "[9990 rows x 58 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YppryO670m8q",
        "outputId": "e797bc42-7872-4ac0-f473-665464102fea"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "scaler = StandardScaler()\r\n",
        "X = scaler.fit_transform(np.array(df1.iloc[:, :-1], dtype = float))\r\n",
        "X_train, X_test_valid, y_train, y_test_valid = train_test_split(X, y, test_size=0.2)\r\n",
        "X_valid, X_test, y_valid, y_test = train_test_split(X_test_valid, y_test_valid, test_size=0.5)\r\n",
        "from keras.models import Sequential\r\n",
        "# Neural network\r\n",
        "model = Sequential()\r\n",
        "model.add(layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)))\r\n",
        "model.add(layers.Dropout(0.25))\r\n",
        "model.add(layers.Dense(64, activation='relu'))\r\n",
        "model.add(layers.Dropout(0.25))\r\n",
        "model.add(layers.Dense(10, activation='softmax'))\r\n",
        "model.compile(optimizer='adam',\r\n",
        "              loss='sparse_categorical_crossentropy',\r\n",
        "              metrics=['accuracy'])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 128)               7552      \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 10)                650       \n",
            "=================================================================\n",
            "Total params: 16,458\n",
            "Trainable params: 16,458\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pYggNDML08WC",
        "outputId": "3fc4f8db-c2e8-4a3b-bb88-5f3063dd1e23"
      },
      "source": [
        "classifier = model.fit(X_train,\r\n",
        "                    y_train,\r\n",
        "                    epochs=500,\r\n",
        "                    batch_size=32, validation_data=(X_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/500\n",
            "250/250 [==============================] - 3s 4ms/step - loss: 1.8698 - accuracy: 0.3278 - val_loss: 1.1033 - val_accuracy: 0.5876\n",
            "Epoch 2/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 1.1558 - accuracy: 0.5932 - val_loss: 0.9015 - val_accuracy: 0.6857\n",
            "Epoch 3/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 1.0173 - accuracy: 0.6392 - val_loss: 0.7896 - val_accuracy: 0.7307\n",
            "Epoch 4/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.9084 - accuracy: 0.6803 - val_loss: 0.7320 - val_accuracy: 0.7588\n",
            "Epoch 5/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.8526 - accuracy: 0.7063 - val_loss: 0.6839 - val_accuracy: 0.7608\n",
            "Epoch 6/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7849 - accuracy: 0.7259 - val_loss: 0.6654 - val_accuracy: 0.7748\n",
            "Epoch 7/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7365 - accuracy: 0.7452 - val_loss: 0.6320 - val_accuracy: 0.7838\n",
            "Epoch 8/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.7102 - accuracy: 0.7513 - val_loss: 0.6046 - val_accuracy: 0.7888\n",
            "Epoch 9/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6535 - accuracy: 0.7676 - val_loss: 0.5887 - val_accuracy: 0.7938\n",
            "Epoch 10/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6642 - accuracy: 0.7678 - val_loss: 0.5546 - val_accuracy: 0.8028\n",
            "Epoch 11/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.6092 - accuracy: 0.7826 - val_loss: 0.5521 - val_accuracy: 0.8048\n",
            "Epoch 12/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5907 - accuracy: 0.7978 - val_loss: 0.5370 - val_accuracy: 0.8088\n",
            "Epoch 13/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5849 - accuracy: 0.8015 - val_loss: 0.5218 - val_accuracy: 0.8178\n",
            "Epoch 14/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.8061 - val_loss: 0.5054 - val_accuracy: 0.8168\n",
            "Epoch 15/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.8031 - val_loss: 0.4857 - val_accuracy: 0.8278\n",
            "Epoch 16/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5213 - accuracy: 0.8159 - val_loss: 0.4820 - val_accuracy: 0.8218\n",
            "Epoch 17/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.5033 - accuracy: 0.8256 - val_loss: 0.4628 - val_accuracy: 0.8308\n",
            "Epoch 18/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4883 - accuracy: 0.8321 - val_loss: 0.4582 - val_accuracy: 0.8338\n",
            "Epoch 19/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4681 - accuracy: 0.8357 - val_loss: 0.4377 - val_accuracy: 0.8549\n",
            "Epoch 20/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4572 - accuracy: 0.8400 - val_loss: 0.4269 - val_accuracy: 0.8398\n",
            "Epoch 21/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4645 - accuracy: 0.8338 - val_loss: 0.4145 - val_accuracy: 0.8539\n",
            "Epoch 22/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4494 - accuracy: 0.8415 - val_loss: 0.4156 - val_accuracy: 0.8529\n",
            "Epoch 23/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4156 - accuracy: 0.8534 - val_loss: 0.4199 - val_accuracy: 0.8498\n",
            "Epoch 24/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4410 - accuracy: 0.8452 - val_loss: 0.4067 - val_accuracy: 0.8579\n",
            "Epoch 25/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4252 - accuracy: 0.8546 - val_loss: 0.3920 - val_accuracy: 0.8659\n",
            "Epoch 26/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4009 - accuracy: 0.8606 - val_loss: 0.3857 - val_accuracy: 0.8669\n",
            "Epoch 27/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4091 - accuracy: 0.8583 - val_loss: 0.3936 - val_accuracy: 0.8689\n",
            "Epoch 28/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4012 - accuracy: 0.8570 - val_loss: 0.3816 - val_accuracy: 0.8679\n",
            "Epoch 29/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.4008 - accuracy: 0.8601 - val_loss: 0.3800 - val_accuracy: 0.8799\n",
            "Epoch 30/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.4024 - accuracy: 0.8593 - val_loss: 0.3827 - val_accuracy: 0.8769\n",
            "Epoch 31/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3778 - accuracy: 0.8668 - val_loss: 0.3798 - val_accuracy: 0.8719\n",
            "Epoch 32/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3750 - accuracy: 0.8717 - val_loss: 0.3695 - val_accuracy: 0.8759\n",
            "Epoch 33/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3517 - accuracy: 0.8791 - val_loss: 0.3649 - val_accuracy: 0.8729\n",
            "Epoch 34/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3511 - accuracy: 0.8817 - val_loss: 0.3666 - val_accuracy: 0.8819\n",
            "Epoch 35/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3610 - accuracy: 0.8718 - val_loss: 0.3608 - val_accuracy: 0.8769\n",
            "Epoch 36/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3499 - accuracy: 0.8759 - val_loss: 0.3521 - val_accuracy: 0.8809\n",
            "Epoch 37/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3300 - accuracy: 0.8817 - val_loss: 0.3526 - val_accuracy: 0.8799\n",
            "Epoch 38/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3315 - accuracy: 0.8852 - val_loss: 0.3491 - val_accuracy: 0.8829\n",
            "Epoch 39/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3233 - accuracy: 0.8917 - val_loss: 0.3421 - val_accuracy: 0.8819\n",
            "Epoch 40/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3266 - accuracy: 0.8873 - val_loss: 0.3459 - val_accuracy: 0.8819\n",
            "Epoch 41/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3128 - accuracy: 0.8854 - val_loss: 0.3514 - val_accuracy: 0.8729\n",
            "Epoch 42/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3039 - accuracy: 0.8951 - val_loss: 0.3461 - val_accuracy: 0.8879\n",
            "Epoch 43/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3239 - accuracy: 0.8898 - val_loss: 0.3414 - val_accuracy: 0.8919\n",
            "Epoch 44/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3090 - accuracy: 0.8911 - val_loss: 0.3317 - val_accuracy: 0.8859\n",
            "Epoch 45/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3181 - accuracy: 0.8867 - val_loss: 0.3211 - val_accuracy: 0.8969\n",
            "Epoch 46/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3120 - accuracy: 0.8888 - val_loss: 0.3347 - val_accuracy: 0.8849\n",
            "Epoch 47/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.3074 - accuracy: 0.8916 - val_loss: 0.3251 - val_accuracy: 0.8939\n",
            "Epoch 48/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2995 - accuracy: 0.8907 - val_loss: 0.3312 - val_accuracy: 0.8949\n",
            "Epoch 49/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2987 - accuracy: 0.8958 - val_loss: 0.3129 - val_accuracy: 0.8959\n",
            "Epoch 50/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2974 - accuracy: 0.8989 - val_loss: 0.3213 - val_accuracy: 0.8909\n",
            "Epoch 51/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2890 - accuracy: 0.8961 - val_loss: 0.3134 - val_accuracy: 0.8939\n",
            "Epoch 52/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2852 - accuracy: 0.9011 - val_loss: 0.3279 - val_accuracy: 0.8869\n",
            "Epoch 53/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2765 - accuracy: 0.9112 - val_loss: 0.3151 - val_accuracy: 0.8959\n",
            "Epoch 54/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2832 - accuracy: 0.8992 - val_loss: 0.3156 - val_accuracy: 0.8929\n",
            "Epoch 55/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2594 - accuracy: 0.9113 - val_loss: 0.3055 - val_accuracy: 0.9009\n",
            "Epoch 56/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2901 - accuracy: 0.9008 - val_loss: 0.3147 - val_accuracy: 0.8859\n",
            "Epoch 57/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2761 - accuracy: 0.9080 - val_loss: 0.3031 - val_accuracy: 0.9019\n",
            "Epoch 58/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2711 - accuracy: 0.9057 - val_loss: 0.3040 - val_accuracy: 0.9009\n",
            "Epoch 59/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2739 - accuracy: 0.9045 - val_loss: 0.3121 - val_accuracy: 0.8909\n",
            "Epoch 60/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2586 - accuracy: 0.9095 - val_loss: 0.3048 - val_accuracy: 0.8929\n",
            "Epoch 61/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2627 - accuracy: 0.9063 - val_loss: 0.2918 - val_accuracy: 0.8949\n",
            "Epoch 62/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2702 - accuracy: 0.9060 - val_loss: 0.3051 - val_accuracy: 0.8939\n",
            "Epoch 63/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2502 - accuracy: 0.9105 - val_loss: 0.2938 - val_accuracy: 0.8979\n",
            "Epoch 64/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2449 - accuracy: 0.9138 - val_loss: 0.3048 - val_accuracy: 0.8929\n",
            "Epoch 65/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2346 - accuracy: 0.9161 - val_loss: 0.3054 - val_accuracy: 0.8959\n",
            "Epoch 66/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2481 - accuracy: 0.9135 - val_loss: 0.2904 - val_accuracy: 0.8979\n",
            "Epoch 67/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2522 - accuracy: 0.9094 - val_loss: 0.3009 - val_accuracy: 0.8909\n",
            "Epoch 68/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2678 - accuracy: 0.9075 - val_loss: 0.2870 - val_accuracy: 0.8919\n",
            "Epoch 69/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2561 - accuracy: 0.9087 - val_loss: 0.2975 - val_accuracy: 0.8939\n",
            "Epoch 70/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2394 - accuracy: 0.9176 - val_loss: 0.2989 - val_accuracy: 0.8979\n",
            "Epoch 71/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2414 - accuracy: 0.9143 - val_loss: 0.2955 - val_accuracy: 0.8949\n",
            "Epoch 72/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2447 - accuracy: 0.9155 - val_loss: 0.2860 - val_accuracy: 0.8919\n",
            "Epoch 73/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2501 - accuracy: 0.9120 - val_loss: 0.2816 - val_accuracy: 0.9069\n",
            "Epoch 74/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2434 - accuracy: 0.9170 - val_loss: 0.2822 - val_accuracy: 0.8959\n",
            "Epoch 75/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2285 - accuracy: 0.9182 - val_loss: 0.2920 - val_accuracy: 0.8919\n",
            "Epoch 76/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2344 - accuracy: 0.9160 - val_loss: 0.2949 - val_accuracy: 0.8929\n",
            "Epoch 77/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2480 - accuracy: 0.9136 - val_loss: 0.3126 - val_accuracy: 0.8909\n",
            "Epoch 78/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2306 - accuracy: 0.9140 - val_loss: 0.3068 - val_accuracy: 0.8929\n",
            "Epoch 79/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2479 - accuracy: 0.9133 - val_loss: 0.3075 - val_accuracy: 0.8969\n",
            "Epoch 80/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9219 - val_loss: 0.2980 - val_accuracy: 0.9039\n",
            "Epoch 81/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.2430 - accuracy: 0.9136 - val_loss: 0.2962 - val_accuracy: 0.9029\n",
            "Epoch 82/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2162 - accuracy: 0.9250 - val_loss: 0.2847 - val_accuracy: 0.9049\n",
            "Epoch 83/500\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.2408 - accuracy: 0.9151 - val_loss: 0.3052 - val_accuracy: 0.9049\n",
            "Epoch 84/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2342 - accuracy: 0.9165 - val_loss: 0.2943 - val_accuracy: 0.9039\n",
            "Epoch 85/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2154 - accuracy: 0.9229 - val_loss: 0.2970 - val_accuracy: 0.9009\n",
            "Epoch 86/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2218 - accuracy: 0.9258 - val_loss: 0.2825 - val_accuracy: 0.9049\n",
            "Epoch 87/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2416 - accuracy: 0.9142 - val_loss: 0.2916 - val_accuracy: 0.8999\n",
            "Epoch 88/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2380 - accuracy: 0.9167 - val_loss: 0.2853 - val_accuracy: 0.8989\n",
            "Epoch 89/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2284 - accuracy: 0.9211 - val_loss: 0.3006 - val_accuracy: 0.9009\n",
            "Epoch 90/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2290 - accuracy: 0.9162 - val_loss: 0.2991 - val_accuracy: 0.8939\n",
            "Epoch 91/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2325 - accuracy: 0.9205 - val_loss: 0.2844 - val_accuracy: 0.9089\n",
            "Epoch 92/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2226 - accuracy: 0.9230 - val_loss: 0.2971 - val_accuracy: 0.8959\n",
            "Epoch 93/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2159 - accuracy: 0.9232 - val_loss: 0.3081 - val_accuracy: 0.8879\n",
            "Epoch 94/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2146 - accuracy: 0.9272 - val_loss: 0.3023 - val_accuracy: 0.8929\n",
            "Epoch 95/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2153 - accuracy: 0.9241 - val_loss: 0.2867 - val_accuracy: 0.8979\n",
            "Epoch 96/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2014 - accuracy: 0.9293 - val_loss: 0.2819 - val_accuracy: 0.9079\n",
            "Epoch 97/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2058 - accuracy: 0.9306 - val_loss: 0.2970 - val_accuracy: 0.9009\n",
            "Epoch 98/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2038 - accuracy: 0.9308 - val_loss: 0.2859 - val_accuracy: 0.9049\n",
            "Epoch 99/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2111 - accuracy: 0.9305 - val_loss: 0.2967 - val_accuracy: 0.8989\n",
            "Epoch 100/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2064 - accuracy: 0.9264 - val_loss: 0.2816 - val_accuracy: 0.9079\n",
            "Epoch 101/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1966 - accuracy: 0.9303 - val_loss: 0.2795 - val_accuracy: 0.9089\n",
            "Epoch 102/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2316 - accuracy: 0.9206 - val_loss: 0.2755 - val_accuracy: 0.9059\n",
            "Epoch 103/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2029 - accuracy: 0.9310 - val_loss: 0.3000 - val_accuracy: 0.9049\n",
            "Epoch 104/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2224 - accuracy: 0.9199 - val_loss: 0.2840 - val_accuracy: 0.9049\n",
            "Epoch 105/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2060 - accuracy: 0.9266 - val_loss: 0.2932 - val_accuracy: 0.9049\n",
            "Epoch 106/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2073 - accuracy: 0.9302 - val_loss: 0.3145 - val_accuracy: 0.8979\n",
            "Epoch 107/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1955 - accuracy: 0.9354 - val_loss: 0.2979 - val_accuracy: 0.9049\n",
            "Epoch 108/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2047 - accuracy: 0.9292 - val_loss: 0.2875 - val_accuracy: 0.9039\n",
            "Epoch 109/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2026 - accuracy: 0.9283 - val_loss: 0.2781 - val_accuracy: 0.9049\n",
            "Epoch 110/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1991 - accuracy: 0.9304 - val_loss: 0.2906 - val_accuracy: 0.8999\n",
            "Epoch 111/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.2160 - accuracy: 0.9289 - val_loss: 0.3021 - val_accuracy: 0.9009\n",
            "Epoch 112/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1942 - accuracy: 0.9290 - val_loss: 0.2982 - val_accuracy: 0.8939\n",
            "Epoch 113/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2040 - accuracy: 0.9304 - val_loss: 0.2964 - val_accuracy: 0.9069\n",
            "Epoch 114/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1913 - accuracy: 0.9328 - val_loss: 0.3085 - val_accuracy: 0.9019\n",
            "Epoch 115/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2073 - accuracy: 0.9240 - val_loss: 0.2852 - val_accuracy: 0.9069\n",
            "Epoch 116/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2015 - accuracy: 0.9284 - val_loss: 0.3047 - val_accuracy: 0.9089\n",
            "Epoch 117/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1925 - accuracy: 0.9335 - val_loss: 0.3127 - val_accuracy: 0.9019\n",
            "Epoch 118/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2035 - accuracy: 0.9302 - val_loss: 0.3176 - val_accuracy: 0.8949\n",
            "Epoch 119/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1995 - accuracy: 0.9269 - val_loss: 0.3070 - val_accuracy: 0.8999\n",
            "Epoch 120/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1887 - accuracy: 0.9335 - val_loss: 0.2992 - val_accuracy: 0.8999\n",
            "Epoch 121/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2078 - accuracy: 0.9252 - val_loss: 0.3208 - val_accuracy: 0.9129\n",
            "Epoch 122/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1919 - accuracy: 0.9328 - val_loss: 0.3014 - val_accuracy: 0.9049\n",
            "Epoch 123/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1976 - accuracy: 0.9293 - val_loss: 0.2986 - val_accuracy: 0.9069\n",
            "Epoch 124/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1990 - accuracy: 0.9263 - val_loss: 0.3075 - val_accuracy: 0.9019\n",
            "Epoch 125/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1977 - accuracy: 0.9337 - val_loss: 0.3216 - val_accuracy: 0.8979\n",
            "Epoch 126/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1971 - accuracy: 0.9325 - val_loss: 0.3072 - val_accuracy: 0.8989\n",
            "Epoch 127/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2124 - accuracy: 0.9303 - val_loss: 0.3034 - val_accuracy: 0.9079\n",
            "Epoch 128/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1844 - accuracy: 0.9388 - val_loss: 0.3076 - val_accuracy: 0.9059\n",
            "Epoch 129/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1898 - accuracy: 0.9309 - val_loss: 0.3170 - val_accuracy: 0.9019\n",
            "Epoch 130/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1694 - accuracy: 0.9380 - val_loss: 0.3154 - val_accuracy: 0.9029\n",
            "Epoch 131/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2013 - accuracy: 0.9322 - val_loss: 0.3037 - val_accuracy: 0.9049\n",
            "Epoch 132/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1918 - accuracy: 0.9343 - val_loss: 0.2900 - val_accuracy: 0.9029\n",
            "Epoch 133/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1928 - accuracy: 0.9330 - val_loss: 0.2913 - val_accuracy: 0.9089\n",
            "Epoch 134/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1875 - accuracy: 0.9355 - val_loss: 0.3005 - val_accuracy: 0.8999\n",
            "Epoch 135/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1793 - accuracy: 0.9395 - val_loss: 0.2841 - val_accuracy: 0.9039\n",
            "Epoch 136/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1798 - accuracy: 0.9388 - val_loss: 0.2918 - val_accuracy: 0.9089\n",
            "Epoch 137/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1859 - accuracy: 0.9342 - val_loss: 0.3132 - val_accuracy: 0.8949\n",
            "Epoch 138/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2034 - accuracy: 0.9372 - val_loss: 0.3031 - val_accuracy: 0.9039\n",
            "Epoch 139/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1983 - accuracy: 0.9331 - val_loss: 0.3058 - val_accuracy: 0.9019\n",
            "Epoch 140/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1909 - accuracy: 0.9350 - val_loss: 0.3009 - val_accuracy: 0.9029\n",
            "Epoch 141/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1920 - accuracy: 0.9375 - val_loss: 0.3106 - val_accuracy: 0.8979\n",
            "Epoch 142/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1712 - accuracy: 0.9357 - val_loss: 0.2948 - val_accuracy: 0.9089\n",
            "Epoch 143/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1974 - accuracy: 0.9372 - val_loss: 0.3031 - val_accuracy: 0.8959\n",
            "Epoch 144/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1876 - accuracy: 0.9339 - val_loss: 0.2969 - val_accuracy: 0.9059\n",
            "Epoch 145/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1753 - accuracy: 0.9425 - val_loss: 0.3000 - val_accuracy: 0.9029\n",
            "Epoch 146/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1699 - accuracy: 0.9399 - val_loss: 0.3144 - val_accuracy: 0.8999\n",
            "Epoch 147/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1853 - accuracy: 0.9366 - val_loss: 0.2981 - val_accuracy: 0.9019\n",
            "Epoch 148/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1866 - accuracy: 0.9342 - val_loss: 0.3002 - val_accuracy: 0.9049\n",
            "Epoch 149/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1772 - accuracy: 0.9376 - val_loss: 0.3317 - val_accuracy: 0.9049\n",
            "Epoch 150/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1824 - accuracy: 0.9372 - val_loss: 0.3286 - val_accuracy: 0.9039\n",
            "Epoch 151/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1759 - accuracy: 0.9354 - val_loss: 0.3331 - val_accuracy: 0.9059\n",
            "Epoch 152/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1954 - accuracy: 0.9353 - val_loss: 0.3486 - val_accuracy: 0.8959\n",
            "Epoch 153/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.2035 - accuracy: 0.9299 - val_loss: 0.3057 - val_accuracy: 0.9069\n",
            "Epoch 154/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1729 - accuracy: 0.9436 - val_loss: 0.3095 - val_accuracy: 0.9009\n",
            "Epoch 155/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1640 - accuracy: 0.9384 - val_loss: 0.3020 - val_accuracy: 0.9059\n",
            "Epoch 156/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1855 - accuracy: 0.9387 - val_loss: 0.3179 - val_accuracy: 0.8989\n",
            "Epoch 157/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1709 - accuracy: 0.9407 - val_loss: 0.3088 - val_accuracy: 0.8979\n",
            "Epoch 158/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1672 - accuracy: 0.9442 - val_loss: 0.3272 - val_accuracy: 0.8959\n",
            "Epoch 159/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1656 - accuracy: 0.9392 - val_loss: 0.3235 - val_accuracy: 0.9029\n",
            "Epoch 160/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1709 - accuracy: 0.9401 - val_loss: 0.3169 - val_accuracy: 0.8959\n",
            "Epoch 161/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1747 - accuracy: 0.9394 - val_loss: 0.3181 - val_accuracy: 0.8979\n",
            "Epoch 162/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9448 - val_loss: 0.3168 - val_accuracy: 0.9049\n",
            "Epoch 163/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1822 - accuracy: 0.9370 - val_loss: 0.3061 - val_accuracy: 0.9029\n",
            "Epoch 164/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1665 - accuracy: 0.9432 - val_loss: 0.3227 - val_accuracy: 0.8959\n",
            "Epoch 165/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1698 - accuracy: 0.9400 - val_loss: 0.2979 - val_accuracy: 0.9029\n",
            "Epoch 166/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1844 - accuracy: 0.9347 - val_loss: 0.2950 - val_accuracy: 0.9069\n",
            "Epoch 167/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1677 - accuracy: 0.9433 - val_loss: 0.3146 - val_accuracy: 0.8999\n",
            "Epoch 168/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1550 - accuracy: 0.9413 - val_loss: 0.3313 - val_accuracy: 0.9029\n",
            "Epoch 169/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1715 - accuracy: 0.9456 - val_loss: 0.3210 - val_accuracy: 0.9009\n",
            "Epoch 170/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1584 - accuracy: 0.9450 - val_loss: 0.3125 - val_accuracy: 0.9019\n",
            "Epoch 171/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1481 - accuracy: 0.9456 - val_loss: 0.3310 - val_accuracy: 0.9029\n",
            "Epoch 172/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1889 - accuracy: 0.9317 - val_loss: 0.3136 - val_accuracy: 0.9099\n",
            "Epoch 173/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1878 - accuracy: 0.9423 - val_loss: 0.3305 - val_accuracy: 0.9089\n",
            "Epoch 174/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1754 - accuracy: 0.9384 - val_loss: 0.3171 - val_accuracy: 0.9069\n",
            "Epoch 175/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1731 - accuracy: 0.9384 - val_loss: 0.3174 - val_accuracy: 0.9009\n",
            "Epoch 176/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1662 - accuracy: 0.9422 - val_loss: 0.3270 - val_accuracy: 0.9089\n",
            "Epoch 177/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1561 - accuracy: 0.9488 - val_loss: 0.3228 - val_accuracy: 0.9069\n",
            "Epoch 178/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1690 - accuracy: 0.9446 - val_loss: 0.3344 - val_accuracy: 0.9039\n",
            "Epoch 179/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1624 - accuracy: 0.9438 - val_loss: 0.2969 - val_accuracy: 0.9069\n",
            "Epoch 180/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1612 - accuracy: 0.9406 - val_loss: 0.3155 - val_accuracy: 0.9039\n",
            "Epoch 181/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1705 - accuracy: 0.9413 - val_loss: 0.3052 - val_accuracy: 0.9059\n",
            "Epoch 182/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1840 - accuracy: 0.9421 - val_loss: 0.3183 - val_accuracy: 0.9079\n",
            "Epoch 183/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1627 - accuracy: 0.9407 - val_loss: 0.3190 - val_accuracy: 0.9009\n",
            "Epoch 184/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1642 - accuracy: 0.9461 - val_loss: 0.3147 - val_accuracy: 0.9069\n",
            "Epoch 185/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1593 - accuracy: 0.9428 - val_loss: 0.3310 - val_accuracy: 0.8939\n",
            "Epoch 186/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1749 - accuracy: 0.9370 - val_loss: 0.3319 - val_accuracy: 0.8999\n",
            "Epoch 187/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1791 - accuracy: 0.9405 - val_loss: 0.3297 - val_accuracy: 0.9059\n",
            "Epoch 188/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1750 - accuracy: 0.9434 - val_loss: 0.3292 - val_accuracy: 0.9079\n",
            "Epoch 189/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1613 - accuracy: 0.9445 - val_loss: 0.3267 - val_accuracy: 0.9009\n",
            "Epoch 190/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1773 - accuracy: 0.9390 - val_loss: 0.3218 - val_accuracy: 0.9069\n",
            "Epoch 191/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1868 - accuracy: 0.9375 - val_loss: 0.3041 - val_accuracy: 0.9069\n",
            "Epoch 192/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9448 - val_loss: 0.3014 - val_accuracy: 0.9069\n",
            "Epoch 193/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1720 - accuracy: 0.9442 - val_loss: 0.3081 - val_accuracy: 0.9079\n",
            "Epoch 194/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1676 - accuracy: 0.9434 - val_loss: 0.3132 - val_accuracy: 0.9159\n",
            "Epoch 195/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1612 - accuracy: 0.9409 - val_loss: 0.3177 - val_accuracy: 0.9029\n",
            "Epoch 196/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1629 - accuracy: 0.9444 - val_loss: 0.3269 - val_accuracy: 0.9089\n",
            "Epoch 197/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1528 - accuracy: 0.9500 - val_loss: 0.3044 - val_accuracy: 0.9119\n",
            "Epoch 198/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1660 - accuracy: 0.9445 - val_loss: 0.3228 - val_accuracy: 0.9119\n",
            "Epoch 199/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1566 - accuracy: 0.9478 - val_loss: 0.3313 - val_accuracy: 0.9089\n",
            "Epoch 200/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1625 - accuracy: 0.9476 - val_loss: 0.3164 - val_accuracy: 0.9119\n",
            "Epoch 201/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1692 - accuracy: 0.9450 - val_loss: 0.3208 - val_accuracy: 0.9049\n",
            "Epoch 202/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1512 - accuracy: 0.9489 - val_loss: 0.3285 - val_accuracy: 0.9079\n",
            "Epoch 203/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1601 - accuracy: 0.9417 - val_loss: 0.3300 - val_accuracy: 0.9009\n",
            "Epoch 204/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1539 - accuracy: 0.9417 - val_loss: 0.3165 - val_accuracy: 0.9069\n",
            "Epoch 205/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1758 - accuracy: 0.9415 - val_loss: 0.3322 - val_accuracy: 0.8979\n",
            "Epoch 206/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1586 - accuracy: 0.9426 - val_loss: 0.3197 - val_accuracy: 0.9009\n",
            "Epoch 207/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9429 - val_loss: 0.3094 - val_accuracy: 0.8969\n",
            "Epoch 208/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1447 - accuracy: 0.9498 - val_loss: 0.3113 - val_accuracy: 0.9119\n",
            "Epoch 209/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1593 - accuracy: 0.9440 - val_loss: 0.3257 - val_accuracy: 0.9049\n",
            "Epoch 210/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1452 - accuracy: 0.9492 - val_loss: 0.3391 - val_accuracy: 0.8949\n",
            "Epoch 211/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9457 - val_loss: 0.3377 - val_accuracy: 0.9009\n",
            "Epoch 212/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1643 - accuracy: 0.9421 - val_loss: 0.3197 - val_accuracy: 0.9029\n",
            "Epoch 213/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1537 - accuracy: 0.9470 - val_loss: 0.3200 - val_accuracy: 0.9049\n",
            "Epoch 214/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1678 - accuracy: 0.9450 - val_loss: 0.3196 - val_accuracy: 0.9039\n",
            "Epoch 215/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1636 - accuracy: 0.9419 - val_loss: 0.3382 - val_accuracy: 0.8989\n",
            "Epoch 216/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1646 - accuracy: 0.9438 - val_loss: 0.3289 - val_accuracy: 0.9029\n",
            "Epoch 217/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1374 - accuracy: 0.9541 - val_loss: 0.3412 - val_accuracy: 0.8999\n",
            "Epoch 218/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1592 - accuracy: 0.9471 - val_loss: 0.3396 - val_accuracy: 0.9059\n",
            "Epoch 219/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1505 - accuracy: 0.9508 - val_loss: 0.3360 - val_accuracy: 0.9069\n",
            "Epoch 220/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1571 - accuracy: 0.9511 - val_loss: 0.3287 - val_accuracy: 0.9039\n",
            "Epoch 221/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1669 - accuracy: 0.9408 - val_loss: 0.3161 - val_accuracy: 0.9089\n",
            "Epoch 222/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1563 - accuracy: 0.9454 - val_loss: 0.3308 - val_accuracy: 0.9069\n",
            "Epoch 223/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1631 - accuracy: 0.9485 - val_loss: 0.3271 - val_accuracy: 0.9049\n",
            "Epoch 224/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1544 - accuracy: 0.9442 - val_loss: 0.3205 - val_accuracy: 0.9069\n",
            "Epoch 225/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1574 - accuracy: 0.9464 - val_loss: 0.3242 - val_accuracy: 0.9059\n",
            "Epoch 226/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1454 - accuracy: 0.9481 - val_loss: 0.3396 - val_accuracy: 0.9109\n",
            "Epoch 227/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1374 - accuracy: 0.9550 - val_loss: 0.3383 - val_accuracy: 0.9009\n",
            "Epoch 228/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1554 - accuracy: 0.9456 - val_loss: 0.3426 - val_accuracy: 0.9039\n",
            "Epoch 229/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9482 - val_loss: 0.3244 - val_accuracy: 0.9059\n",
            "Epoch 230/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1617 - accuracy: 0.9466 - val_loss: 0.3545 - val_accuracy: 0.9039\n",
            "Epoch 231/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1611 - accuracy: 0.9465 - val_loss: 0.3237 - val_accuracy: 0.9029\n",
            "Epoch 232/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1515 - accuracy: 0.9474 - val_loss: 0.3462 - val_accuracy: 0.8989\n",
            "Epoch 233/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1576 - accuracy: 0.9428 - val_loss: 0.3475 - val_accuracy: 0.9039\n",
            "Epoch 234/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1606 - accuracy: 0.9456 - val_loss: 0.3414 - val_accuracy: 0.9019\n",
            "Epoch 235/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1643 - accuracy: 0.9447 - val_loss: 0.3529 - val_accuracy: 0.8969\n",
            "Epoch 236/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1676 - accuracy: 0.9460 - val_loss: 0.3337 - val_accuracy: 0.9059\n",
            "Epoch 237/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1502 - accuracy: 0.9477 - val_loss: 0.3565 - val_accuracy: 0.9009\n",
            "Epoch 238/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1527 - accuracy: 0.9470 - val_loss: 0.3387 - val_accuracy: 0.9029\n",
            "Epoch 239/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1318 - accuracy: 0.9527 - val_loss: 0.3391 - val_accuracy: 0.9119\n",
            "Epoch 240/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1472 - accuracy: 0.9494 - val_loss: 0.3491 - val_accuracy: 0.9069\n",
            "Epoch 241/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1341 - accuracy: 0.9526 - val_loss: 0.3231 - val_accuracy: 0.9029\n",
            "Epoch 242/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1397 - accuracy: 0.9528 - val_loss: 0.3359 - val_accuracy: 0.9029\n",
            "Epoch 243/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1591 - accuracy: 0.9476 - val_loss: 0.3376 - val_accuracy: 0.9009\n",
            "Epoch 244/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1581 - accuracy: 0.9461 - val_loss: 0.3271 - val_accuracy: 0.9059\n",
            "Epoch 245/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1385 - accuracy: 0.9495 - val_loss: 0.3574 - val_accuracy: 0.9019\n",
            "Epoch 246/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9538 - val_loss: 0.3412 - val_accuracy: 0.8999\n",
            "Epoch 247/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1489 - accuracy: 0.9469 - val_loss: 0.3341 - val_accuracy: 0.9069\n",
            "Epoch 248/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9433 - val_loss: 0.3349 - val_accuracy: 0.8999\n",
            "Epoch 249/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9541 - val_loss: 0.3336 - val_accuracy: 0.9029\n",
            "Epoch 250/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1508 - accuracy: 0.9502 - val_loss: 0.3321 - val_accuracy: 0.9069\n",
            "Epoch 251/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1723 - accuracy: 0.9405 - val_loss: 0.3432 - val_accuracy: 0.9099\n",
            "Epoch 252/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1725 - accuracy: 0.9448 - val_loss: 0.3357 - val_accuracy: 0.9119\n",
            "Epoch 253/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1448 - accuracy: 0.9530 - val_loss: 0.3261 - val_accuracy: 0.9119\n",
            "Epoch 254/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1495 - accuracy: 0.9472 - val_loss: 0.3604 - val_accuracy: 0.9009\n",
            "Epoch 255/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1395 - accuracy: 0.9523 - val_loss: 0.3448 - val_accuracy: 0.9029\n",
            "Epoch 256/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1557 - accuracy: 0.9497 - val_loss: 0.3470 - val_accuracy: 0.9029\n",
            "Epoch 257/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1508 - accuracy: 0.9516 - val_loss: 0.3503 - val_accuracy: 0.9089\n",
            "Epoch 258/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1410 - accuracy: 0.9495 - val_loss: 0.3395 - val_accuracy: 0.8949\n",
            "Epoch 259/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1385 - accuracy: 0.9512 - val_loss: 0.3299 - val_accuracy: 0.9049\n",
            "Epoch 260/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1575 - accuracy: 0.9439 - val_loss: 0.3356 - val_accuracy: 0.9069\n",
            "Epoch 261/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1451 - accuracy: 0.9509 - val_loss: 0.3294 - val_accuracy: 0.9029\n",
            "Epoch 262/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1584 - accuracy: 0.9486 - val_loss: 0.3302 - val_accuracy: 0.9139\n",
            "Epoch 263/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9466 - val_loss: 0.3312 - val_accuracy: 0.9119\n",
            "Epoch 264/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9484 - val_loss: 0.3421 - val_accuracy: 0.9049\n",
            "Epoch 265/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1411 - accuracy: 0.9515 - val_loss: 0.3440 - val_accuracy: 0.9009\n",
            "Epoch 266/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1517 - accuracy: 0.9504 - val_loss: 0.3439 - val_accuracy: 0.9059\n",
            "Epoch 267/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1551 - accuracy: 0.9460 - val_loss: 0.3559 - val_accuracy: 0.9059\n",
            "Epoch 268/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1350 - accuracy: 0.9533 - val_loss: 0.3652 - val_accuracy: 0.8949\n",
            "Epoch 269/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1507 - accuracy: 0.9468 - val_loss: 0.3874 - val_accuracy: 0.8929\n",
            "Epoch 270/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1489 - accuracy: 0.9508 - val_loss: 0.3674 - val_accuracy: 0.9099\n",
            "Epoch 271/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1525 - accuracy: 0.9486 - val_loss: 0.3599 - val_accuracy: 0.9089\n",
            "Epoch 272/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1427 - accuracy: 0.9476 - val_loss: 0.3501 - val_accuracy: 0.9139\n",
            "Epoch 273/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1479 - accuracy: 0.9492 - val_loss: 0.3634 - val_accuracy: 0.9069\n",
            "Epoch 274/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1498 - accuracy: 0.9524 - val_loss: 0.3609 - val_accuracy: 0.9019\n",
            "Epoch 275/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1681 - accuracy: 0.9457 - val_loss: 0.3363 - val_accuracy: 0.9069\n",
            "Epoch 276/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1404 - accuracy: 0.9516 - val_loss: 0.3536 - val_accuracy: 0.8999\n",
            "Epoch 277/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1364 - accuracy: 0.9502 - val_loss: 0.3529 - val_accuracy: 0.9039\n",
            "Epoch 278/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1348 - accuracy: 0.9524 - val_loss: 0.3444 - val_accuracy: 0.8969\n",
            "Epoch 279/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1592 - accuracy: 0.9436 - val_loss: 0.3507 - val_accuracy: 0.8999\n",
            "Epoch 280/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9525 - val_loss: 0.3394 - val_accuracy: 0.9039\n",
            "Epoch 281/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9538 - val_loss: 0.3530 - val_accuracy: 0.8999\n",
            "Epoch 282/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1383 - accuracy: 0.9529 - val_loss: 0.3600 - val_accuracy: 0.8989\n",
            "Epoch 283/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1274 - accuracy: 0.9533 - val_loss: 0.3522 - val_accuracy: 0.9019\n",
            "Epoch 284/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9520 - val_loss: 0.3585 - val_accuracy: 0.9009\n",
            "Epoch 285/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9531 - val_loss: 0.3474 - val_accuracy: 0.9039\n",
            "Epoch 286/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1427 - accuracy: 0.9521 - val_loss: 0.3465 - val_accuracy: 0.9059\n",
            "Epoch 287/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1351 - accuracy: 0.9552 - val_loss: 0.3621 - val_accuracy: 0.8979\n",
            "Epoch 288/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1509 - accuracy: 0.9493 - val_loss: 0.3492 - val_accuracy: 0.9099\n",
            "Epoch 289/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1297 - accuracy: 0.9570 - val_loss: 0.3421 - val_accuracy: 0.9049\n",
            "Epoch 290/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1499 - accuracy: 0.9534 - val_loss: 0.3443 - val_accuracy: 0.9079\n",
            "Epoch 291/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1526 - accuracy: 0.9474 - val_loss: 0.3461 - val_accuracy: 0.9099\n",
            "Epoch 292/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1439 - accuracy: 0.9513 - val_loss: 0.3497 - val_accuracy: 0.9049\n",
            "Epoch 293/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1434 - accuracy: 0.9530 - val_loss: 0.3519 - val_accuracy: 0.9029\n",
            "Epoch 294/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9523 - val_loss: 0.3515 - val_accuracy: 0.9039\n",
            "Epoch 295/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1393 - accuracy: 0.9546 - val_loss: 0.3484 - val_accuracy: 0.9089\n",
            "Epoch 296/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9488 - val_loss: 0.3348 - val_accuracy: 0.9089\n",
            "Epoch 297/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1530 - accuracy: 0.9463 - val_loss: 0.3466 - val_accuracy: 0.9009\n",
            "Epoch 298/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1398 - accuracy: 0.9549 - val_loss: 0.3599 - val_accuracy: 0.8979\n",
            "Epoch 299/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1460 - accuracy: 0.9440 - val_loss: 0.3326 - val_accuracy: 0.9079\n",
            "Epoch 300/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1423 - accuracy: 0.9519 - val_loss: 0.3283 - val_accuracy: 0.9089\n",
            "Epoch 301/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1304 - accuracy: 0.9557 - val_loss: 0.3338 - val_accuracy: 0.9009\n",
            "Epoch 302/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9492 - val_loss: 0.3520 - val_accuracy: 0.8989\n",
            "Epoch 303/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1329 - accuracy: 0.9540 - val_loss: 0.3320 - val_accuracy: 0.9119\n",
            "Epoch 304/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1358 - accuracy: 0.9512 - val_loss: 0.3419 - val_accuracy: 0.9049\n",
            "Epoch 305/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1466 - accuracy: 0.9529 - val_loss: 0.3391 - val_accuracy: 0.9079\n",
            "Epoch 306/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1384 - accuracy: 0.9527 - val_loss: 0.3553 - val_accuracy: 0.9079\n",
            "Epoch 307/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1341 - accuracy: 0.9559 - val_loss: 0.3819 - val_accuracy: 0.8969\n",
            "Epoch 308/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.9557 - val_loss: 0.3566 - val_accuracy: 0.9089\n",
            "Epoch 309/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1509 - accuracy: 0.9516 - val_loss: 0.3741 - val_accuracy: 0.8979\n",
            "Epoch 310/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.9578 - val_loss: 0.3561 - val_accuracy: 0.9079\n",
            "Epoch 311/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1294 - accuracy: 0.9568 - val_loss: 0.3743 - val_accuracy: 0.9039\n",
            "Epoch 312/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1478 - accuracy: 0.9479 - val_loss: 0.3623 - val_accuracy: 0.9089\n",
            "Epoch 313/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1213 - accuracy: 0.9587 - val_loss: 0.3635 - val_accuracy: 0.9029\n",
            "Epoch 314/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1471 - accuracy: 0.9491 - val_loss: 0.3447 - val_accuracy: 0.9089\n",
            "Epoch 315/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9531 - val_loss: 0.3634 - val_accuracy: 0.9019\n",
            "Epoch 316/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1501 - accuracy: 0.9481 - val_loss: 0.3611 - val_accuracy: 0.9059\n",
            "Epoch 317/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1354 - accuracy: 0.9567 - val_loss: 0.3537 - val_accuracy: 0.9069\n",
            "Epoch 318/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1499 - accuracy: 0.9514 - val_loss: 0.3637 - val_accuracy: 0.9029\n",
            "Epoch 319/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1488 - accuracy: 0.9521 - val_loss: 0.3546 - val_accuracy: 0.9029\n",
            "Epoch 320/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9519 - val_loss: 0.3549 - val_accuracy: 0.9019\n",
            "Epoch 321/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1253 - accuracy: 0.9552 - val_loss: 0.3491 - val_accuracy: 0.9119\n",
            "Epoch 322/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1247 - accuracy: 0.9608 - val_loss: 0.3693 - val_accuracy: 0.8949\n",
            "Epoch 323/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1376 - accuracy: 0.9513 - val_loss: 0.3567 - val_accuracy: 0.9049\n",
            "Epoch 324/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1422 - accuracy: 0.9489 - val_loss: 0.3320 - val_accuracy: 0.9089\n",
            "Epoch 325/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1392 - accuracy: 0.9491 - val_loss: 0.3607 - val_accuracy: 0.8979\n",
            "Epoch 326/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1330 - accuracy: 0.9524 - val_loss: 0.3654 - val_accuracy: 0.9029\n",
            "Epoch 327/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1275 - accuracy: 0.9576 - val_loss: 0.3576 - val_accuracy: 0.9029\n",
            "Epoch 328/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1480 - accuracy: 0.9545 - val_loss: 0.3470 - val_accuracy: 0.9009\n",
            "Epoch 329/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1347 - accuracy: 0.9561 - val_loss: 0.3388 - val_accuracy: 0.9069\n",
            "Epoch 330/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1496 - accuracy: 0.9468 - val_loss: 0.3338 - val_accuracy: 0.9089\n",
            "Epoch 331/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1352 - accuracy: 0.9550 - val_loss: 0.3258 - val_accuracy: 0.9089\n",
            "Epoch 332/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1433 - accuracy: 0.9520 - val_loss: 0.3349 - val_accuracy: 0.9059\n",
            "Epoch 333/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1425 - accuracy: 0.9540 - val_loss: 0.3370 - val_accuracy: 0.9149\n",
            "Epoch 334/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1267 - accuracy: 0.9581 - val_loss: 0.3495 - val_accuracy: 0.9049\n",
            "Epoch 335/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1428 - accuracy: 0.9528 - val_loss: 0.3554 - val_accuracy: 0.9059\n",
            "Epoch 336/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1228 - accuracy: 0.9567 - val_loss: 0.3734 - val_accuracy: 0.9079\n",
            "Epoch 337/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1412 - accuracy: 0.9539 - val_loss: 0.3598 - val_accuracy: 0.9069\n",
            "Epoch 338/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1401 - accuracy: 0.9516 - val_loss: 0.3511 - val_accuracy: 0.9069\n",
            "Epoch 339/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1198 - accuracy: 0.9606 - val_loss: 0.3337 - val_accuracy: 0.9049\n",
            "Epoch 340/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1247 - accuracy: 0.9586 - val_loss: 0.3458 - val_accuracy: 0.9079\n",
            "Epoch 341/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1298 - accuracy: 0.9582 - val_loss: 0.3442 - val_accuracy: 0.8949\n",
            "Epoch 342/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1290 - accuracy: 0.9559 - val_loss: 0.3473 - val_accuracy: 0.9069\n",
            "Epoch 343/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1440 - accuracy: 0.9512 - val_loss: 0.3503 - val_accuracy: 0.9079\n",
            "Epoch 344/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1293 - accuracy: 0.9535 - val_loss: 0.3547 - val_accuracy: 0.9039\n",
            "Epoch 345/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1396 - accuracy: 0.9529 - val_loss: 0.3672 - val_accuracy: 0.9009\n",
            "Epoch 346/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9536 - val_loss: 0.3323 - val_accuracy: 0.9129\n",
            "Epoch 347/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1292 - accuracy: 0.9578 - val_loss: 0.3213 - val_accuracy: 0.9039\n",
            "Epoch 348/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1413 - accuracy: 0.9542 - val_loss: 0.3338 - val_accuracy: 0.9149\n",
            "Epoch 349/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1359 - accuracy: 0.9529 - val_loss: 0.3506 - val_accuracy: 0.9059\n",
            "Epoch 350/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1252 - accuracy: 0.9559 - val_loss: 0.3497 - val_accuracy: 0.9079\n",
            "Epoch 351/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1359 - accuracy: 0.9541 - val_loss: 0.3505 - val_accuracy: 0.9099\n",
            "Epoch 352/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1268 - accuracy: 0.9581 - val_loss: 0.3312 - val_accuracy: 0.9089\n",
            "Epoch 353/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1192 - accuracy: 0.9613 - val_loss: 0.3560 - val_accuracy: 0.9039\n",
            "Epoch 354/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1522 - accuracy: 0.9486 - val_loss: 0.3653 - val_accuracy: 0.9089\n",
            "Epoch 355/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1397 - accuracy: 0.9552 - val_loss: 0.3500 - val_accuracy: 0.9109\n",
            "Epoch 356/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1307 - accuracy: 0.9557 - val_loss: 0.3923 - val_accuracy: 0.8999\n",
            "Epoch 357/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1227 - accuracy: 0.9572 - val_loss: 0.3561 - val_accuracy: 0.9139\n",
            "Epoch 358/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1218 - accuracy: 0.9569 - val_loss: 0.3737 - val_accuracy: 0.9019\n",
            "Epoch 359/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1306 - accuracy: 0.9551 - val_loss: 0.3758 - val_accuracy: 0.9039\n",
            "Epoch 360/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1335 - accuracy: 0.9554 - val_loss: 0.3488 - val_accuracy: 0.9059\n",
            "Epoch 361/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1428 - accuracy: 0.9526 - val_loss: 0.3714 - val_accuracy: 0.9019\n",
            "Epoch 362/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9528 - val_loss: 0.3801 - val_accuracy: 0.8959\n",
            "Epoch 363/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1422 - accuracy: 0.9505 - val_loss: 0.3696 - val_accuracy: 0.9009\n",
            "Epoch 364/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1377 - accuracy: 0.9561 - val_loss: 0.3696 - val_accuracy: 0.9049\n",
            "Epoch 365/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9546 - val_loss: 0.3690 - val_accuracy: 0.8989\n",
            "Epoch 366/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1215 - accuracy: 0.9572 - val_loss: 0.3746 - val_accuracy: 0.9029\n",
            "Epoch 367/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1271 - accuracy: 0.9583 - val_loss: 0.3669 - val_accuracy: 0.9049\n",
            "Epoch 368/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1267 - accuracy: 0.9566 - val_loss: 0.3758 - val_accuracy: 0.8999\n",
            "Epoch 369/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1328 - accuracy: 0.9533 - val_loss: 0.3947 - val_accuracy: 0.8999\n",
            "Epoch 370/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1440 - accuracy: 0.9480 - val_loss: 0.3640 - val_accuracy: 0.8979\n",
            "Epoch 371/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1137 - accuracy: 0.9612 - val_loss: 0.3758 - val_accuracy: 0.9079\n",
            "Epoch 372/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1180 - accuracy: 0.9598 - val_loss: 0.3700 - val_accuracy: 0.9029\n",
            "Epoch 373/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1377 - accuracy: 0.9541 - val_loss: 0.3625 - val_accuracy: 0.9049\n",
            "Epoch 374/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1313 - accuracy: 0.9557 - val_loss: 0.3319 - val_accuracy: 0.9049\n",
            "Epoch 375/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1282 - accuracy: 0.9560 - val_loss: 0.3743 - val_accuracy: 0.8929\n",
            "Epoch 376/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1296 - accuracy: 0.9534 - val_loss: 0.3743 - val_accuracy: 0.9049\n",
            "Epoch 377/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1210 - accuracy: 0.9588 - val_loss: 0.3599 - val_accuracy: 0.9069\n",
            "Epoch 378/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1136 - accuracy: 0.9648 - val_loss: 0.3548 - val_accuracy: 0.9039\n",
            "Epoch 379/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1341 - accuracy: 0.9555 - val_loss: 0.3412 - val_accuracy: 0.9079\n",
            "Epoch 380/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1289 - accuracy: 0.9567 - val_loss: 0.3600 - val_accuracy: 0.9079\n",
            "Epoch 381/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1240 - accuracy: 0.9584 - val_loss: 0.3657 - val_accuracy: 0.9119\n",
            "Epoch 382/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1271 - accuracy: 0.9541 - val_loss: 0.3739 - val_accuracy: 0.9099\n",
            "Epoch 383/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1249 - accuracy: 0.9561 - val_loss: 0.3551 - val_accuracy: 0.9049\n",
            "Epoch 384/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1472 - accuracy: 0.9581 - val_loss: 0.3743 - val_accuracy: 0.8989\n",
            "Epoch 385/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1145 - accuracy: 0.9583 - val_loss: 0.3831 - val_accuracy: 0.8989\n",
            "Epoch 386/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1448 - accuracy: 0.9496 - val_loss: 0.3903 - val_accuracy: 0.8989\n",
            "Epoch 387/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1406 - accuracy: 0.9530 - val_loss: 0.3633 - val_accuracy: 0.9089\n",
            "Epoch 388/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1354 - accuracy: 0.9542 - val_loss: 0.3643 - val_accuracy: 0.9119\n",
            "Epoch 389/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1370 - accuracy: 0.9523 - val_loss: 0.3711 - val_accuracy: 0.9009\n",
            "Epoch 390/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1291 - accuracy: 0.9567 - val_loss: 0.3725 - val_accuracy: 0.9019\n",
            "Epoch 391/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1183 - accuracy: 0.9593 - val_loss: 0.3834 - val_accuracy: 0.9049\n",
            "Epoch 392/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1232 - accuracy: 0.9549 - val_loss: 0.3843 - val_accuracy: 0.8999\n",
            "Epoch 393/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1287 - accuracy: 0.9589 - val_loss: 0.3667 - val_accuracy: 0.9029\n",
            "Epoch 394/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1486 - accuracy: 0.9489 - val_loss: 0.3695 - val_accuracy: 0.9059\n",
            "Epoch 395/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1123 - accuracy: 0.9625 - val_loss: 0.3418 - val_accuracy: 0.9039\n",
            "Epoch 396/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1474 - accuracy: 0.9499 - val_loss: 0.3599 - val_accuracy: 0.9029\n",
            "Epoch 397/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1274 - accuracy: 0.9568 - val_loss: 0.3782 - val_accuracy: 0.8969\n",
            "Epoch 398/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1194 - accuracy: 0.9579 - val_loss: 0.4005 - val_accuracy: 0.8989\n",
            "Epoch 399/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1325 - accuracy: 0.9578 - val_loss: 0.3886 - val_accuracy: 0.9099\n",
            "Epoch 400/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1323 - accuracy: 0.9591 - val_loss: 0.3800 - val_accuracy: 0.9099\n",
            "Epoch 401/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1240 - accuracy: 0.9549 - val_loss: 0.3766 - val_accuracy: 0.9089\n",
            "Epoch 402/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1405 - accuracy: 0.9534 - val_loss: 0.3825 - val_accuracy: 0.9079\n",
            "Epoch 403/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1342 - accuracy: 0.9568 - val_loss: 0.3788 - val_accuracy: 0.9119\n",
            "Epoch 404/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1251 - accuracy: 0.9572 - val_loss: 0.3865 - val_accuracy: 0.8999\n",
            "Epoch 405/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1156 - accuracy: 0.9597 - val_loss: 0.3929 - val_accuracy: 0.9029\n",
            "Epoch 406/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1378 - accuracy: 0.9555 - val_loss: 0.3428 - val_accuracy: 0.9009\n",
            "Epoch 407/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1356 - accuracy: 0.9548 - val_loss: 0.3371 - val_accuracy: 0.9109\n",
            "Epoch 408/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1170 - accuracy: 0.9621 - val_loss: 0.3455 - val_accuracy: 0.9029\n",
            "Epoch 409/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1252 - accuracy: 0.9551 - val_loss: 0.3476 - val_accuracy: 0.9059\n",
            "Epoch 410/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1166 - accuracy: 0.9579 - val_loss: 0.3670 - val_accuracy: 0.9039\n",
            "Epoch 411/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1109 - accuracy: 0.9629 - val_loss: 0.3488 - val_accuracy: 0.8979\n",
            "Epoch 412/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1365 - accuracy: 0.9538 - val_loss: 0.3488 - val_accuracy: 0.9029\n",
            "Epoch 413/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1276 - accuracy: 0.9537 - val_loss: 0.3798 - val_accuracy: 0.9029\n",
            "Epoch 414/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1210 - accuracy: 0.9597 - val_loss: 0.3910 - val_accuracy: 0.8979\n",
            "Epoch 415/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1352 - accuracy: 0.9558 - val_loss: 0.3906 - val_accuracy: 0.8999\n",
            "Epoch 416/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1082 - accuracy: 0.9643 - val_loss: 0.3898 - val_accuracy: 0.8919\n",
            "Epoch 417/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1314 - accuracy: 0.9571 - val_loss: 0.3922 - val_accuracy: 0.9019\n",
            "Epoch 418/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1253 - accuracy: 0.9565 - val_loss: 0.3686 - val_accuracy: 0.9059\n",
            "Epoch 419/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1641 - accuracy: 0.9457 - val_loss: 0.3844 - val_accuracy: 0.9059\n",
            "Epoch 420/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1330 - accuracy: 0.9599 - val_loss: 0.3579 - val_accuracy: 0.9079\n",
            "Epoch 421/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1301 - accuracy: 0.9549 - val_loss: 0.3697 - val_accuracy: 0.9039\n",
            "Epoch 422/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1260 - accuracy: 0.9550 - val_loss: 0.3858 - val_accuracy: 0.9059\n",
            "Epoch 423/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1108 - accuracy: 0.9630 - val_loss: 0.3725 - val_accuracy: 0.9159\n",
            "Epoch 424/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1263 - accuracy: 0.9592 - val_loss: 0.3721 - val_accuracy: 0.9089\n",
            "Epoch 425/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1087 - accuracy: 0.9635 - val_loss: 0.3652 - val_accuracy: 0.9089\n",
            "Epoch 426/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1256 - accuracy: 0.9610 - val_loss: 0.3378 - val_accuracy: 0.9129\n",
            "Epoch 427/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1369 - accuracy: 0.9566 - val_loss: 0.3658 - val_accuracy: 0.8999\n",
            "Epoch 428/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1376 - accuracy: 0.9517 - val_loss: 0.3821 - val_accuracy: 0.9079\n",
            "Epoch 429/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1204 - accuracy: 0.9539 - val_loss: 0.3679 - val_accuracy: 0.9029\n",
            "Epoch 430/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1142 - accuracy: 0.9580 - val_loss: 0.3781 - val_accuracy: 0.9059\n",
            "Epoch 431/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9573 - val_loss: 0.3783 - val_accuracy: 0.9039\n",
            "Epoch 432/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.9565 - val_loss: 0.3800 - val_accuracy: 0.9009\n",
            "Epoch 433/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1330 - accuracy: 0.9552 - val_loss: 0.3758 - val_accuracy: 0.9109\n",
            "Epoch 434/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9630 - val_loss: 0.3864 - val_accuracy: 0.9079\n",
            "Epoch 435/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1164 - accuracy: 0.9615 - val_loss: 0.3797 - val_accuracy: 0.9029\n",
            "Epoch 436/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9581 - val_loss: 0.3769 - val_accuracy: 0.9049\n",
            "Epoch 437/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1364 - accuracy: 0.9562 - val_loss: 0.3657 - val_accuracy: 0.9029\n",
            "Epoch 438/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1214 - accuracy: 0.9571 - val_loss: 0.3478 - val_accuracy: 0.9099\n",
            "Epoch 439/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1149 - accuracy: 0.9604 - val_loss: 0.3833 - val_accuracy: 0.9049\n",
            "Epoch 440/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1509 - accuracy: 0.9501 - val_loss: 0.3716 - val_accuracy: 0.9009\n",
            "Epoch 441/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1325 - accuracy: 0.9570 - val_loss: 0.3883 - val_accuracy: 0.8939\n",
            "Epoch 442/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1340 - accuracy: 0.9565 - val_loss: 0.3778 - val_accuracy: 0.9079\n",
            "Epoch 443/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1312 - accuracy: 0.9565 - val_loss: 0.3491 - val_accuracy: 0.9069\n",
            "Epoch 444/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1284 - accuracy: 0.9621 - val_loss: 0.3683 - val_accuracy: 0.9119\n",
            "Epoch 445/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1149 - accuracy: 0.9594 - val_loss: 0.3773 - val_accuracy: 0.8999\n",
            "Epoch 446/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1371 - accuracy: 0.9531 - val_loss: 0.3708 - val_accuracy: 0.9009\n",
            "Epoch 447/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1126 - accuracy: 0.9630 - val_loss: 0.3849 - val_accuracy: 0.9099\n",
            "Epoch 448/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1331 - accuracy: 0.9543 - val_loss: 0.3632 - val_accuracy: 0.9049\n",
            "Epoch 449/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1154 - accuracy: 0.9613 - val_loss: 0.4011 - val_accuracy: 0.8989\n",
            "Epoch 450/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1201 - accuracy: 0.9585 - val_loss: 0.3656 - val_accuracy: 0.9049\n",
            "Epoch 451/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1395 - accuracy: 0.9528 - val_loss: 0.3683 - val_accuracy: 0.9079\n",
            "Epoch 452/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1306 - accuracy: 0.9581 - val_loss: 0.3697 - val_accuracy: 0.9079\n",
            "Epoch 453/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1141 - accuracy: 0.9578 - val_loss: 0.3836 - val_accuracy: 0.9049\n",
            "Epoch 454/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1073 - accuracy: 0.9591 - val_loss: 0.3777 - val_accuracy: 0.9059\n",
            "Epoch 455/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1153 - accuracy: 0.9583 - val_loss: 0.3639 - val_accuracy: 0.9079\n",
            "Epoch 456/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1122 - accuracy: 0.9603 - val_loss: 0.3732 - val_accuracy: 0.9059\n",
            "Epoch 457/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1183 - accuracy: 0.9588 - val_loss: 0.3827 - val_accuracy: 0.9049\n",
            "Epoch 458/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1130 - accuracy: 0.9620 - val_loss: 0.3837 - val_accuracy: 0.9049\n",
            "Epoch 459/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1156 - accuracy: 0.9642 - val_loss: 0.3760 - val_accuracy: 0.9089\n",
            "Epoch 460/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1185 - accuracy: 0.9553 - val_loss: 0.3703 - val_accuracy: 0.9089\n",
            "Epoch 461/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1315 - accuracy: 0.9562 - val_loss: 0.4089 - val_accuracy: 0.9089\n",
            "Epoch 462/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1163 - accuracy: 0.9582 - val_loss: 0.3596 - val_accuracy: 0.9089\n",
            "Epoch 463/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1241 - accuracy: 0.9632 - val_loss: 0.3773 - val_accuracy: 0.9119\n",
            "Epoch 464/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1258 - accuracy: 0.9593 - val_loss: 0.3570 - val_accuracy: 0.9049\n",
            "Epoch 465/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1307 - accuracy: 0.9578 - val_loss: 0.3665 - val_accuracy: 0.9069\n",
            "Epoch 466/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1286 - accuracy: 0.9572 - val_loss: 0.3604 - val_accuracy: 0.9079\n",
            "Epoch 467/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1334 - accuracy: 0.9547 - val_loss: 0.4017 - val_accuracy: 0.9009\n",
            "Epoch 468/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1272 - accuracy: 0.9568 - val_loss: 0.3745 - val_accuracy: 0.9109\n",
            "Epoch 469/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1166 - accuracy: 0.9609 - val_loss: 0.3952 - val_accuracy: 0.9009\n",
            "Epoch 470/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1424 - accuracy: 0.9549 - val_loss: 0.3746 - val_accuracy: 0.9079\n",
            "Epoch 471/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1231 - accuracy: 0.9614 - val_loss: 0.4034 - val_accuracy: 0.9059\n",
            "Epoch 472/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1366 - accuracy: 0.9588 - val_loss: 0.3696 - val_accuracy: 0.9049\n",
            "Epoch 473/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1305 - accuracy: 0.9548 - val_loss: 0.3752 - val_accuracy: 0.9079\n",
            "Epoch 474/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1226 - accuracy: 0.9551 - val_loss: 0.3946 - val_accuracy: 0.9079\n",
            "Epoch 475/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1209 - accuracy: 0.9608 - val_loss: 0.3895 - val_accuracy: 0.8969\n",
            "Epoch 476/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1256 - accuracy: 0.9595 - val_loss: 0.3870 - val_accuracy: 0.9039\n",
            "Epoch 477/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1265 - accuracy: 0.9579 - val_loss: 0.4010 - val_accuracy: 0.8989\n",
            "Epoch 478/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1124 - accuracy: 0.9595 - val_loss: 0.3837 - val_accuracy: 0.9089\n",
            "Epoch 479/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1080 - accuracy: 0.9661 - val_loss: 0.3896 - val_accuracy: 0.9039\n",
            "Epoch 480/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1276 - accuracy: 0.9595 - val_loss: 0.4144 - val_accuracy: 0.8999\n",
            "Epoch 481/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1324 - accuracy: 0.9602 - val_loss: 0.3717 - val_accuracy: 0.9049\n",
            "Epoch 482/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1206 - accuracy: 0.9592 - val_loss: 0.3858 - val_accuracy: 0.9049\n",
            "Epoch 483/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1155 - accuracy: 0.9628 - val_loss: 0.3668 - val_accuracy: 0.9059\n",
            "Epoch 484/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1156 - accuracy: 0.9607 - val_loss: 0.3917 - val_accuracy: 0.9029\n",
            "Epoch 485/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1217 - accuracy: 0.9633 - val_loss: 0.3838 - val_accuracy: 0.9069\n",
            "Epoch 486/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1074 - accuracy: 0.9631 - val_loss: 0.3786 - val_accuracy: 0.9039\n",
            "Epoch 487/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1147 - accuracy: 0.9604 - val_loss: 0.3746 - val_accuracy: 0.9079\n",
            "Epoch 488/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1112 - accuracy: 0.9619 - val_loss: 0.3713 - val_accuracy: 0.8999\n",
            "Epoch 489/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1260 - accuracy: 0.9614 - val_loss: 0.3600 - val_accuracy: 0.9119\n",
            "Epoch 490/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1308 - accuracy: 0.9584 - val_loss: 0.3672 - val_accuracy: 0.9079\n",
            "Epoch 491/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1161 - accuracy: 0.9604 - val_loss: 0.3748 - val_accuracy: 0.9039\n",
            "Epoch 492/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1070 - accuracy: 0.9632 - val_loss: 0.3932 - val_accuracy: 0.9009\n",
            "Epoch 493/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1386 - accuracy: 0.9539 - val_loss: 0.3868 - val_accuracy: 0.8999\n",
            "Epoch 494/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.0960 - accuracy: 0.9676 - val_loss: 0.4004 - val_accuracy: 0.8989\n",
            "Epoch 495/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1215 - accuracy: 0.9586 - val_loss: 0.3912 - val_accuracy: 0.9059\n",
            "Epoch 496/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1157 - accuracy: 0.9602 - val_loss: 0.3929 - val_accuracy: 0.9059\n",
            "Epoch 497/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1048 - accuracy: 0.9640 - val_loss: 0.4073 - val_accuracy: 0.9049\n",
            "Epoch 498/500\n",
            "250/250 [==============================] - 1s 2ms/step - loss: 0.1101 - accuracy: 0.9619 - val_loss: 0.4068 - val_accuracy: 0.9009\n",
            "Epoch 499/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1228 - accuracy: 0.9600 - val_loss: 0.3812 - val_accuracy: 0.9009\n",
            "Epoch 500/500\n",
            "250/250 [==============================] - 1s 3ms/step - loss: 0.1276 - accuracy: 0.9554 - val_loss: 0.3741 - val_accuracy: 0.9099\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OoWAbNPN1B8Q",
        "outputId": "182c04dc-478b-4ebc-bf02-8d465e14da6d"
      },
      "source": [
        "test_loss, test_acc  = model.evaluate(X_test, y_test, batch_size=128)\r\n",
        "print(\"The test loss is :\",test_loss, \"\\nThe test accuracy is :\",test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 2ms/step - loss: 0.4067 - accuracy: 0.9069\n",
            "The test loss is : 0.40665799379348755 \n",
            "The test accuracy is : 0.9069069027900696\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "id": "MfKcn6292TPG",
        "outputId": "e4f42278-7a21-4afc-9e7b-372da617df30"
      },
      "source": [
        "N = 500\r\n",
        "plt.style.use(\"ggplot\")\r\n",
        "plt.figure()\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"loss\"], label=\"train_loss\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"val_loss\"], label=\"val_loss\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"accuracy\"], label=\"train_acc\")\r\n",
        "plt.plot(np.arange(0, N), classifier.history[\"val_accuracy\"], label=\"val_acc\")\r\n",
        "plt.title(\"Training Loss and Accuracy on Music Dataset\")\r\n",
        "plt.xlabel(\"Epoch #\")\r\n",
        "plt.ylabel(\"Loss/Accuracy\")\r\n",
        "plt.legend(loc=\"lower left\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f7e3a1fd9e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}